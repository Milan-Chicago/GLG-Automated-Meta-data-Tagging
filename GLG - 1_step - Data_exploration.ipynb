{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data and python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make plot s appear after the code cell\n",
    "%matplotlib inline \n",
    "\n",
    "# data processing libraries\n",
    "import pandas as pd\n",
    "\n",
    "# display wider columns in pandas data frames where necessary\n",
    "pd.set_option('max_colwidth',150)\n",
    "\n",
    "# data visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#detect language\n",
    "from langdetect import detect\n",
    "\n",
    "# supporting libraries\n",
    "import re\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file location of the data\n",
    "input_folder = './data/'\n",
    "output_folder = './transition_files/'\n",
    "\n",
    "file_name = 'all-the-news-2-1.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "df_data = pd.read_csv(input_folder + file_name, #file location\n",
    "                      encoding = \"ISO-8859-1\", #deal with texts in different formats\n",
    "                     )\n",
    "\n",
    "# display first row of the data frame\n",
    "print(df_data.shape)\n",
    "df_data.head(1).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_data (df):\n",
    "    \"\"\"\n",
    "    check data types of values in the pandas data frame and number of missing values\n",
    "    \n",
    "    input:\n",
    "        df - as pandas data frame to analyze\n",
    "    \n",
    "    output:\n",
    "        pandas data frame with column name, \n",
    "                                column data type, \n",
    "                                the data type of actual value in the column\n",
    "                                number of missing values\n",
    "                                value example\n",
    "    \"\"\"\n",
    "    df_data_types = []\n",
    "    actual_data_types = []\n",
    "    num_missing = []\n",
    "    values = []\n",
    "    columns = list(df_data.columns)\n",
    "    \n",
    "    for column in df_data.columns:\n",
    "        #selecting only non missing values in the column\n",
    "        df_tmp = df[df[column].isnull() == False]\n",
    "        \n",
    "        #count number of missing values\n",
    "        num_missing.append(len(df) - len(df_tmp))\n",
    "        \n",
    "        #getting column data type\n",
    "        dtype = str(df_tmp[column].dtypes)\n",
    "        df_data_types.append(dtype)\n",
    "                \n",
    "        #getting data type of an actual value\n",
    "        actual_value = df_tmp[column].iloc[0]\n",
    "        m = re.search(\"'.+'\", str(type(actual_value)))\n",
    "        if m:\n",
    "            dtype = m.group(0)\n",
    "        else:\n",
    "            dtype =  ''   \n",
    "        actual_data_types.append(dtype)\n",
    "        values.append(actual_value)\n",
    "        \n",
    "    #create data frame with data types comparison\n",
    "    df_result = pd.DataFrame({\n",
    "                              'data type': df_data_types,\n",
    "                              'actual data type': actual_data_types,\n",
    "                              'number of missing values': num_missing,\n",
    "                              '% of missing values': [round(n / len(df) * 100,2) for n in num_missing],\n",
    "                              'value example': values\n",
    "                             }, index=columns)\n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking data quality\n",
    "print('datatype = \"object\" means the column has string and/or missing values in it.')\n",
    "check_data(df_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:<br>We have >60% of articles that are assigned to some section in a paper. So we can use some for model validattion.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Section data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"NOTE: section data is noisy!\")\n",
    "print(\"Number of sections per publication:\")\n",
    "s = pd.DataFrame(df_data.groupby('publication')['section'].nunique())\n",
    "s.describe(percentiles=[0.6,0.7,0.8,0.9,0.95]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of articles per section:\")\n",
    "s = pd.DataFrame(df_data.groupby('section')['article'].count())\n",
    "s.describe(percentiles=[0.6,0.7,0.8,0.9,0.95]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate number_of_sections per publication\n",
    "df_data['number_of_sections'] = df_data.groupby('publication')['section'].transform(\"nunique\")\n",
    "df_data[['publication', 'section', 'number_of_sections']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_thr = 10\n",
    "upper_thr = 50\n",
    "print(\"Take only publications with reasonable number of sections (%2d-%2d)\"%(lower_thr, upper_thr))\n",
    "\n",
    "df_test = df_data[(df_data['number_of_sections'] >= lower_thr) &\n",
    "                  (df_data['number_of_sections'] <= upper_thr)\n",
    "                 ]\n",
    "print(\"Number of articles:\", len(df_test), \" out of\", len(df_data))\n",
    "print(\"\\nPublications:\", set(df_test['publication']))\n",
    "print(\"\\nSections:\\n\", set(df_test['section']))\n",
    "s = pd.DataFrame(df_test.groupby('publication')['section'].nunique())\n",
    "s.describe(percentiles=[0.6,0.7,0.8,0.9,0.95]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sections to consider:**\n",
    "- music\n",
    "- culture \n",
    "- schools-brief\n",
    "- business\n",
    "- awards\n",
    "- travel | outdoor\n",
    "- sports\n",
    "- real-estate\n",
    "- politics\n",
    "- tech\n",
    "- economic-indicators | finance-and-economics | economic-and-financial-indicators |  \n",
    "- health\n",
    "\n",
    "\n",
    "etc. (needs to be discussed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of articles per section IN SELECTED PUBLICATIONS:\")\n",
    "s = pd.DataFrame(df_test.groupby('section')['article'].count())\n",
    "s.describe(percentiles=[0.6,0.7,0.8,0.9,0.95]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate text length of each article in symbols\n",
    "df_data[\"text_length\"] = df_data['article'].fillna(\"\").apply(len)\n",
    "\n",
    "#look at descriptive statistic\n",
    "pd.DataFrame(df_data[\"text_length\"].describe(percentiles=[0.01,0.05,0.25,0.5,0.75,0.95,0.99])).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example: text with less than 150 symbols\n",
    "df_data[df_data[\"text_length\"] < 150]['article'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete reviews with length less than 10th percentile and more than 95th percentile of the sample\n",
    "#since they are suspiciously short or long\n",
    "#calculate length percentiles\n",
    "pct10 = df_data[\"text_length\"].quantile(0.10)\n",
    "pct95 = df_data[\"text_length\"].quantile(0.95)\n",
    "\n",
    "print('minimum length: ',df_data[\"text_length\"].min())\n",
    "print('maximum  length: ',df_data[\"text_length\"].max())\n",
    "print('\\n10th percentile: ', pct10, '\\n95th percentile: ', pct95)\n",
    "\n",
    "#delete suspicious values\n",
    "print('\\n\\nData size before deletion: ', len(df_data))\n",
    "df_data = df_data[(df_data[\"text_length\"] >= pct10) & (df_data[\"text_length\"] <= pct95)]\n",
    "print('Data size after deletion:  ', len(df_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at descriptive statistics\n",
    "print(\"Total number of observations: \", len(df_data))\n",
    "pd.DataFrame(df_data[\"text_length\"].describe(percentiles=[0.01,0.05,0.25,0.5,0.75,0.95,0.99])).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** Articles with missing text were deleted from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test languages of every 500th article\n",
    "def define_language(df, column):\n",
    "    # detect languages for each text in the column\n",
    "    lang_list = []\n",
    "    for i in range(len(df)):\n",
    "        text = df[column].iloc[i]\n",
    "        try:\n",
    "            language = detect(text)\n",
    "        except:\n",
    "            language = \"error\"\n",
    "        lang_list.append(language)\n",
    "\n",
    "    return lang_list\n",
    "\n",
    "#############################################################\n",
    "df_test = df_data.iloc[::500]\n",
    "df_test['article_language'] = define_language(df_test, \"article\") \n",
    "df_test['article_language'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get article posting date in python format where possible \n",
    "#NOTE: if string can not be converted it is replaced with missing value NaT\n",
    "df_data['py_date'] = pd.to_datetime(df_data['date'], format='%Y-%m-%d %H:%M:%S', errors='coerce')\n",
    "df_data[['date', 'py_date']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data['py_date'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of articles per year:\")\n",
    "df_data['py_year'] = df_data['py_date'].dt.year\n",
    "df_data['py_year'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of articles per month:\")\n",
    "df_data['py_month'] = df_data['py_date'].dt.month\n",
    "df_data['py_month'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of months per year:\")\n",
    "print(df_data.groupby(\"py_year\")['py_month'].nunique().sort_index())\n",
    "\n",
    "print(\"\\nCovered months in 2020:\", set(df_data[df_data['py_year'] == 2020]['py_month']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(df_data[df_data['py_year'] == 2020]['py_month'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Conclusions:\n",
    "- We have enough data with predefined labels to test Topic Modeling algorithm.\n",
    "- Only first 4 months are covered in 2020 (if it has any importance to capture Covid-19 news)\n",
    "- There are non-English articles! (need to clean that)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "305.455px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
