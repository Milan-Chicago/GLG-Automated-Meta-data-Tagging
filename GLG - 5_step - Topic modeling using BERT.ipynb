{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Idea:\n",
    "Our solution: LDA + BERT based embeddings of noun phrases and verbs :\n",
    "- Each noun phrase and verb in the texts is  transformed to embedding vector using Universal Sentence Encoder (transformer based on BERT)\n",
    "- Embedding vectors from (a) are clustered (HDBSCAN + UNET)\n",
    "- Words/phrases with embedding vectors closest to the centers of resulting clusters form key word/phrase\n",
    "- Each text in the training sample is converted to collection of key-phrases by replacing its noun phrases and verbs with keyword/phrases and deleting other words\n",
    "- LDA is performed on the transformed texts\n",
    "\n",
    "\n",
    "**Reference:**<br>\n",
    "- Daniel Cer, Yinfei Yang, Sheng-yi Kong, Nan Hua, Nicole Limtiaco, Rhomni St. John, Noah Constant, Mario Guajardo-CÃ©spedes, Steve Yuan, Chris Tar, Yun-Hsuan Sung, Brian Strope, Ray Kurzweil. **Universal Sentence Encoder.** *arXiv:1803.11175, 2018.*\n",
    "- McInnes, L, Healy, J, **UMAP: Uniform Manifold Approximation and Projection for Dimension Reduction**, *ArXiv e-prints 1802.03426, 2018*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "clNUUp3MUO2t"
   },
   "source": [
    "# Load data and python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1622131163361,
     "user": {
      "displayName": "Tatiana Chebonenko",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgwGu7u_TizJ74HmaMD0AtIfiksMdhRYrfZtevXzQ=s64",
      "userId": "10264586744881678851"
     },
     "user_tz": 240
    },
    "id": "7dYQIbH6UO2u"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.2.0\n",
      "module https://tfhub.dev/google/universal-sentence-encoder-large/5 loaded\n"
     ]
    }
   ],
   "source": [
    "# data processing libraries\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "# display wider columns in pandas data frames where necessary\n",
    "pd.set_option('max_colwidth',150)\n",
    "\n",
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "#Load the Universal Sentence Encoder's TF Hub module\n",
    "module_url = \"https://tfhub.dev/google/universal-sentence-encoder-large/5\"\n",
    "model = hub.load(module_url)\n",
    "print (\"module %s loaded\" % module_url)\n",
    "\n",
    "import umap\n",
    "import hdbscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train.shape: (33982, 12)\n",
      "df_train.shape: Index(['date', 'author', 'title', 'url', 'section', 'publication',\n",
      "       'first_10_sents', 'list_of_first_10_sents', 'list_of_verb_lemmas',\n",
      "       'noun_phrases', 'list_of_nouns', 'list_of_lemmas'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"./transition_files/train.tsv\", sep='\\t')\n",
    "print(\"df_train.shape:\", df_train.shape)\n",
    "print(\"df_train.shape:\",df_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Bxk10XYUqNp"
   },
   "source": [
    "# Getting text clusters through sentence embedding comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1622131190534,
     "user": {
      "displayName": "Tatiana Chebonenko",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgwGu7u_TizJ74HmaMD0AtIfiksMdhRYrfZtevXzQ=s64",
      "userId": "10264586744881678851"
     },
     "user_tz": 240
    },
    "id": "MsgF9abaX2Bn"
   },
   "outputs": [],
   "source": [
    "def get_embeddings(input):\n",
    "    return model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_embeddings(df_data, column = \"word\", N_batches=1):\n",
    "    #split data into N batches\n",
    "    N = N_batches\n",
    "\n",
    "    part = int(len(df_data)/N)\n",
    "    print(N, \"batches with\", part + 1, column + \"s each\")\n",
    "\n",
    "    #get embeddings for each N words\n",
    "    index = 0\n",
    "    batch_num = 0\n",
    "    list_dfs = []\n",
    "\n",
    "    while index < len(df_data): \n",
    "        df_tmp = df_data.iloc[index : index + part].copy()\n",
    "        df_tmp = df_tmp.reset_index(drop=True)\n",
    "        print (\"Batch number:\", batch_num + 1, \"out of \", N)\n",
    "\n",
    "        df_batch_embeddings = pd.DataFrame(get_embeddings(list(df_tmp[column])).numpy())\n",
    "\n",
    "        num_embeddings = df_batch_embeddings.shape[1]\n",
    "        columns = [\"emb_\" + str(i) for i in range(512)]\n",
    "        df_tmp[columns] = df_batch_embeddings\n",
    "\n",
    "        list_dfs.append(df_tmp)\n",
    "        batch_num = batch_num + 1\n",
    "        index = index + part\n",
    "\n",
    "    #concatinate batches into single dataset\n",
    "    df_emb = pd.concat(list_dfs)\n",
    "\n",
    "    return df_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [rise, big emerging economy, china, india, steady march, globalisation, surge, number, people, business, tourism, result, demand, visa, unpreceden...\n",
       "1    [pfizer, commitment, corporate social responsibility csr, drugs giant talk, responsibility, society, world, access, product, work, ngos, global he...\n",
       "2    [week, federal reserve, interest rate, time, year, world, central bank, rate, recent year, long spell, course, chart, outcome, americas rate rise,...\n",
       "3    [cruise line, wave, year, nearly, holiday, sea, result, december 18th carnival, worlds largest operator, global market, fullyear earning, demand, ...\n",
       "4    [investors, calendar year, buoyant mood, unexpected event, consensus, respect, view, investor, market price, column, potential surprise, definitio...\n",
       "Name: noun_phrases, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['noun_phrases'] = df_train['noun_phrases'].str[2:-2]\n",
    "df_train['noun_phrases'] = df_train['noun_phrases'].str.lower().str.split(\"', '\")\n",
    "df_train['noun_phrases'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['rise', 'big emerging economy', 'china', 'india', 'steady march'], 1417049)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_NPs = list(df_train['noun_phrases'])\n",
    "all_NPs = [np for l in all_NPs for np in l if len(np)>0]\n",
    "all_NPs[:5], len(all_NPs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[emerging, led, wanting, travel, granted, Upgrade, travel, apply, submit, streamline, scrap]'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['list_of_verb_lemmas'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                               [merging, led, wanting, travel, granted, upgrade, travel, apply, submit, streamline, scra]\n",
       "1    [rided, embracing, insists, gain, strengthen, improve, deterred, seeking, intends, shift, domiciled, rejoiced, saved, paid, outraged, promised, im...\n",
       "2    [aised, ended, celebrate, tried, lift, forced, reverse, cut, help, understand, upgrade, strike, wish, save, spend, try, escape, slashing, encourag...\n",
       "3      [race, booked, improve, announced, control, demand, peaking, piling, based, got, moving, upgrade, increase, announced, establish, aimed, based, ad]\n",
       "4    [tart, caught, proved, reflected, like, suggest, judged, betting, expect, upgrade, weakens, having, pushed, tighten, buy, priced, doubt, tighten, ...\n",
       "Name: list_of_verb_lemmas, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['list_of_verb_lemmas'] = df_train['list_of_verb_lemmas'].str[2:-2]\n",
    "df_train['list_of_verb_lemmas'] = df_train['list_of_verb_lemmas'].str.lower().str.split(\", \")\n",
    "df_train['list_of_verb_lemmas'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['merging', 'led', 'wanting', 'travel', 'granted'], 675330)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_Vs = list(df_train['list_of_verb_lemmas'])\n",
    "all_Vs = [v for l in all_Vs for v in l if len(v)>0]\n",
    "all_Vs[:5], len(all_Vs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "419327"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words =  list(set(all_NPs + all_Vs))\n",
    "len(set(all_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "0_QElB-4UM2z",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ar art installation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>st louis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>passive investment vehicle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nicotinefueled train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>outrageous controversial statement</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 word\n",
       "0                 ar art installation\n",
       "1                            st louis\n",
       "2          passive investment vehicle\n",
       "3                nicotinefueled train\n",
       "4  outrageous controversial statement"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_words = pd.DataFrame({'word': all_words})\n",
    "df_words.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 batches with 4194 words each\n",
      "Batch number: 1 out of  100\n",
      "Batch number: 2 out of  100\n",
      "Batch number: 3 out of  100\n",
      "Batch number: 4 out of  100\n",
      "Batch number: 5 out of  100\n",
      "Batch number: 6 out of  100\n",
      "Batch number: 7 out of  100\n",
      "Batch number: 8 out of  100\n",
      "Batch number: 9 out of  100\n",
      "Batch number: 10 out of  100\n",
      "Batch number: 11 out of  100\n",
      "Batch number: 12 out of  100\n",
      "Batch number: 13 out of  100\n",
      "Batch number: 14 out of  100\n",
      "Batch number: 15 out of  100\n",
      "Batch number: 16 out of  100\n",
      "Batch number: 17 out of  100\n",
      "Batch number: 18 out of  100\n",
      "Batch number: 19 out of  100\n",
      "Batch number: 20 out of  100\n",
      "Batch number: 21 out of  100\n",
      "Batch number: 22 out of  100\n",
      "Batch number: 23 out of  100\n",
      "Batch number: 24 out of  100\n",
      "Batch number: 25 out of  100\n",
      "Batch number: 26 out of  100\n",
      "Batch number: 27 out of  100\n",
      "Batch number: 28 out of  100\n",
      "Batch number: 29 out of  100\n",
      "Batch number: 30 out of  100\n",
      "Batch number: 31 out of  100\n",
      "Batch number: 32 out of  100\n",
      "Batch number: 33 out of  100\n",
      "Batch number: 34 out of  100\n",
      "Batch number: 35 out of  100\n",
      "Batch number: 36 out of  100\n",
      "Batch number: 37 out of  100\n",
      "Batch number: 38 out of  100\n",
      "Batch number: 39 out of  100\n",
      "Batch number: 40 out of  100\n",
      "Batch number: 41 out of  100\n",
      "Batch number: 42 out of  100\n",
      "Batch number: 43 out of  100\n",
      "Batch number: 44 out of  100\n",
      "Batch number: 45 out of  100\n",
      "Batch number: 46 out of  100\n",
      "Batch number: 47 out of  100\n",
      "Batch number: 48 out of  100\n",
      "Batch number: 49 out of  100\n",
      "Batch number: 50 out of  100\n",
      "Batch number: 51 out of  100\n",
      "Batch number: 52 out of  100\n",
      "Batch number: 53 out of  100\n",
      "Batch number: 54 out of  100\n",
      "Batch number: 55 out of  100\n",
      "Batch number: 56 out of  100\n",
      "Batch number: 57 out of  100\n",
      "Batch number: 58 out of  100\n",
      "Batch number: 59 out of  100\n",
      "Batch number: 60 out of  100\n",
      "Batch number: 61 out of  100\n",
      "Batch number: 62 out of  100\n",
      "Batch number: 63 out of  100\n",
      "Batch number: 64 out of  100\n",
      "Batch number: 65 out of  100\n",
      "Batch number: 66 out of  100\n",
      "Batch number: 67 out of  100\n",
      "Batch number: 68 out of  100\n",
      "Batch number: 69 out of  100\n",
      "Batch number: 70 out of  100\n",
      "Batch number: 71 out of  100\n",
      "Batch number: 72 out of  100\n",
      "Batch number: 73 out of  100\n",
      "Batch number: 74 out of  100\n",
      "Batch number: 75 out of  100\n",
      "Batch number: 76 out of  100\n",
      "Batch number: 77 out of  100\n",
      "Batch number: 78 out of  100\n",
      "Batch number: 79 out of  100\n",
      "Batch number: 80 out of  100\n",
      "Batch number: 81 out of  100\n",
      "Batch number: 82 out of  100\n",
      "Batch number: 83 out of  100\n",
      "Batch number: 84 out of  100\n",
      "Batch number: 85 out of  100\n",
      "Batch number: 86 out of  100\n",
      "Batch number: 87 out of  100\n",
      "Batch number: 88 out of  100\n",
      "Batch number: 89 out of  100\n",
      "Batch number: 90 out of  100\n",
      "Batch number: 91 out of  100\n",
      "Batch number: 92 out of  100\n",
      "Batch number: 93 out of  100\n",
      "Batch number: 94 out of  100\n",
      "Batch number: 95 out of  100\n",
      "Batch number: 96 out of  100\n",
      "Batch number: 97 out of  100\n",
      "Batch number: 98 out of  100\n",
      "Batch number: 99 out of  100\n",
      "Batch number: 100 out of  100\n",
      "Batch number: 101 out of  100\n",
      "CPU times: user 50min 24s, sys: 2min 12s, total: 52min 37s\n",
      "Wall time: 5min 3s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>emb_0</th>\n",
       "      <th>emb_1</th>\n",
       "      <th>emb_2</th>\n",
       "      <th>emb_3</th>\n",
       "      <th>emb_4</th>\n",
       "      <th>emb_5</th>\n",
       "      <th>emb_6</th>\n",
       "      <th>emb_7</th>\n",
       "      <th>emb_8</th>\n",
       "      <th>...</th>\n",
       "      <th>emb_502</th>\n",
       "      <th>emb_503</th>\n",
       "      <th>emb_504</th>\n",
       "      <th>emb_505</th>\n",
       "      <th>emb_506</th>\n",
       "      <th>emb_507</th>\n",
       "      <th>emb_508</th>\n",
       "      <th>emb_509</th>\n",
       "      <th>emb_510</th>\n",
       "      <th>emb_511</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ar art installation</td>\n",
       "      <td>0.020122</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>0.012315</td>\n",
       "      <td>0.029161</td>\n",
       "      <td>-0.001987</td>\n",
       "      <td>-0.042893</td>\n",
       "      <td>-0.069303</td>\n",
       "      <td>-0.028578</td>\n",
       "      <td>-0.031996</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003335</td>\n",
       "      <td>-0.017962</td>\n",
       "      <td>0.055528</td>\n",
       "      <td>-0.029352</td>\n",
       "      <td>0.046558</td>\n",
       "      <td>0.058642</td>\n",
       "      <td>0.027662</td>\n",
       "      <td>0.008687</td>\n",
       "      <td>0.004643</td>\n",
       "      <td>0.015045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>st louis</td>\n",
       "      <td>0.025534</td>\n",
       "      <td>-0.046714</td>\n",
       "      <td>-0.019601</td>\n",
       "      <td>0.010690</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>-0.040848</td>\n",
       "      <td>-0.023721</td>\n",
       "      <td>-0.039049</td>\n",
       "      <td>-0.056522</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.062257</td>\n",
       "      <td>-0.069166</td>\n",
       "      <td>0.062389</td>\n",
       "      <td>-0.046099</td>\n",
       "      <td>-0.073728</td>\n",
       "      <td>0.037204</td>\n",
       "      <td>-0.011648</td>\n",
       "      <td>-0.019840</td>\n",
       "      <td>-0.031511</td>\n",
       "      <td>-0.064533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>passive investment vehicle</td>\n",
       "      <td>0.031301</td>\n",
       "      <td>-0.088394</td>\n",
       "      <td>-0.007285</td>\n",
       "      <td>0.043246</td>\n",
       "      <td>0.006554</td>\n",
       "      <td>-0.005797</td>\n",
       "      <td>-0.048646</td>\n",
       "      <td>0.060434</td>\n",
       "      <td>0.053056</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.045909</td>\n",
       "      <td>0.051535</td>\n",
       "      <td>-0.043772</td>\n",
       "      <td>-0.007596</td>\n",
       "      <td>0.085432</td>\n",
       "      <td>0.065079</td>\n",
       "      <td>0.022551</td>\n",
       "      <td>-0.070039</td>\n",
       "      <td>0.006904</td>\n",
       "      <td>-0.003364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nicotinefueled train</td>\n",
       "      <td>0.063141</td>\n",
       "      <td>0.028098</td>\n",
       "      <td>-0.080064</td>\n",
       "      <td>0.013365</td>\n",
       "      <td>0.008811</td>\n",
       "      <td>-0.047909</td>\n",
       "      <td>-0.034389</td>\n",
       "      <td>0.037728</td>\n",
       "      <td>0.027899</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011127</td>\n",
       "      <td>-0.027788</td>\n",
       "      <td>0.025181</td>\n",
       "      <td>-0.000268</td>\n",
       "      <td>0.000478</td>\n",
       "      <td>-0.014033</td>\n",
       "      <td>0.016180</td>\n",
       "      <td>0.033930</td>\n",
       "      <td>-0.026782</td>\n",
       "      <td>0.018010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>outrageous controversial statement</td>\n",
       "      <td>-0.034301</td>\n",
       "      <td>-0.025041</td>\n",
       "      <td>-0.005895</td>\n",
       "      <td>0.019051</td>\n",
       "      <td>0.020005</td>\n",
       "      <td>0.038791</td>\n",
       "      <td>-0.044979</td>\n",
       "      <td>0.060520</td>\n",
       "      <td>-0.018211</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.040841</td>\n",
       "      <td>-0.068408</td>\n",
       "      <td>0.037497</td>\n",
       "      <td>-0.004308</td>\n",
       "      <td>0.010036</td>\n",
       "      <td>0.020996</td>\n",
       "      <td>0.030820</td>\n",
       "      <td>0.062054</td>\n",
       "      <td>0.017476</td>\n",
       "      <td>0.065568</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã 513 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 word     emb_0     emb_1     emb_2     emb_3  \\\n",
       "0                 ar art installation  0.020122  0.000388  0.012315  0.029161   \n",
       "1                            st louis  0.025534 -0.046714 -0.019601  0.010690   \n",
       "2          passive investment vehicle  0.031301 -0.088394 -0.007285  0.043246   \n",
       "3                nicotinefueled train  0.063141  0.028098 -0.080064  0.013365   \n",
       "4  outrageous controversial statement -0.034301 -0.025041 -0.005895  0.019051   \n",
       "\n",
       "      emb_4     emb_5     emb_6     emb_7     emb_8  ...   emb_502   emb_503  \\\n",
       "0 -0.001987 -0.042893 -0.069303 -0.028578 -0.031996  ...  0.003335 -0.017962   \n",
       "1  0.000144 -0.040848 -0.023721 -0.039049 -0.056522  ... -0.062257 -0.069166   \n",
       "2  0.006554 -0.005797 -0.048646  0.060434  0.053056  ... -0.045909  0.051535   \n",
       "3  0.008811 -0.047909 -0.034389  0.037728  0.027899  ... -0.011127 -0.027788   \n",
       "4  0.020005  0.038791 -0.044979  0.060520 -0.018211  ... -0.040841 -0.068408   \n",
       "\n",
       "    emb_504   emb_505   emb_506   emb_507   emb_508   emb_509   emb_510  \\\n",
       "0  0.055528 -0.029352  0.046558  0.058642  0.027662  0.008687  0.004643   \n",
       "1  0.062389 -0.046099 -0.073728  0.037204 -0.011648 -0.019840 -0.031511   \n",
       "2 -0.043772 -0.007596  0.085432  0.065079  0.022551 -0.070039  0.006904   \n",
       "3  0.025181 -0.000268  0.000478 -0.014033  0.016180  0.033930 -0.026782   \n",
       "4  0.037497 -0.004308  0.010036  0.020996  0.030820  0.062054  0.017476   \n",
       "\n",
       "    emb_511  \n",
       "0  0.015045  \n",
       "1 -0.064533  \n",
       "2 -0.003364  \n",
       "3  0.018010  \n",
       "4  0.065568  \n",
       "\n",
       "[5 rows x 513 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#creating word2vec matrix\n",
    "df_w2v = get_word_embeddings(df_words, column = \"word\", N_batches=100)\n",
    "df_w2v.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>emb_0</th>\n",
       "      <th>emb_1</th>\n",
       "      <th>emb_2</th>\n",
       "      <th>emb_3</th>\n",
       "      <th>emb_4</th>\n",
       "      <th>emb_5</th>\n",
       "      <th>emb_6</th>\n",
       "      <th>emb_7</th>\n",
       "      <th>emb_8</th>\n",
       "      <th>...</th>\n",
       "      <th>emb_502</th>\n",
       "      <th>emb_503</th>\n",
       "      <th>emb_504</th>\n",
       "      <th>emb_505</th>\n",
       "      <th>emb_506</th>\n",
       "      <th>emb_507</th>\n",
       "      <th>emb_508</th>\n",
       "      <th>emb_509</th>\n",
       "      <th>emb_510</th>\n",
       "      <th>emb_511</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ar art installation</td>\n",
       "      <td>0.020122</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>0.012315</td>\n",
       "      <td>0.029161</td>\n",
       "      <td>-0.001987</td>\n",
       "      <td>-0.042893</td>\n",
       "      <td>-0.069303</td>\n",
       "      <td>-0.028578</td>\n",
       "      <td>-0.031996</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003335</td>\n",
       "      <td>-0.017962</td>\n",
       "      <td>0.055528</td>\n",
       "      <td>-0.029352</td>\n",
       "      <td>0.046558</td>\n",
       "      <td>0.058642</td>\n",
       "      <td>0.027662</td>\n",
       "      <td>0.008687</td>\n",
       "      <td>0.004643</td>\n",
       "      <td>0.015045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3246</th>\n",
       "      <td>preacher</td>\n",
       "      <td>-0.019613</td>\n",
       "      <td>-0.003985</td>\n",
       "      <td>0.020316</td>\n",
       "      <td>-0.021083</td>\n",
       "      <td>0.007729</td>\n",
       "      <td>0.035804</td>\n",
       "      <td>0.052691</td>\n",
       "      <td>-0.028713</td>\n",
       "      <td>0.005826</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.032107</td>\n",
       "      <td>0.020066</td>\n",
       "      <td>-0.045432</td>\n",
       "      <td>-0.023615</td>\n",
       "      <td>-0.030040</td>\n",
       "      <td>0.028765</td>\n",
       "      <td>-0.031556</td>\n",
       "      <td>0.043194</td>\n",
       "      <td>-0.001436</td>\n",
       "      <td>-0.047522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2299</th>\n",
       "      <td>pixabaythe centers</td>\n",
       "      <td>0.114876</td>\n",
       "      <td>0.002980</td>\n",
       "      <td>-0.048121</td>\n",
       "      <td>0.031062</td>\n",
       "      <td>0.019793</td>\n",
       "      <td>-0.031369</td>\n",
       "      <td>-0.051993</td>\n",
       "      <td>-0.012182</td>\n",
       "      <td>-0.071958</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011845</td>\n",
       "      <td>-0.012947</td>\n",
       "      <td>0.008947</td>\n",
       "      <td>-0.029392</td>\n",
       "      <td>0.051362</td>\n",
       "      <td>0.036043</td>\n",
       "      <td>0.023112</td>\n",
       "      <td>0.007506</td>\n",
       "      <td>0.024925</td>\n",
       "      <td>-0.047059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã 513 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     word     emb_0     emb_1     emb_2     emb_3     emb_4  \\\n",
       "0     ar art installation  0.020122  0.000388  0.012315  0.029161 -0.001987   \n",
       "3246             preacher -0.019613 -0.003985  0.020316 -0.021083  0.007729   \n",
       "2299   pixabaythe centers  0.114876  0.002980 -0.048121  0.031062  0.019793   \n",
       "\n",
       "         emb_5     emb_6     emb_7     emb_8  ...   emb_502   emb_503  \\\n",
       "0    -0.042893 -0.069303 -0.028578 -0.031996  ...  0.003335 -0.017962   \n",
       "3246  0.035804  0.052691 -0.028713  0.005826  ... -0.032107  0.020066   \n",
       "2299 -0.031369 -0.051993 -0.012182 -0.071958  ...  0.011845 -0.012947   \n",
       "\n",
       "       emb_504   emb_505   emb_506   emb_507   emb_508   emb_509   emb_510  \\\n",
       "0     0.055528 -0.029352  0.046558  0.058642  0.027662  0.008687  0.004643   \n",
       "3246 -0.045432 -0.023615 -0.030040  0.028765 -0.031556  0.043194 -0.001436   \n",
       "2299  0.008947 -0.029392  0.051362  0.036043  0.023112  0.007506  0.024925   \n",
       "\n",
       "       emb_511  \n",
       "0     0.015045  \n",
       "3246 -0.047522  \n",
       "2299 -0.047059  \n",
       "\n",
       "[3 rows x 513 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_w2v.iloc[::150001]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality reduction \n",
    "UMAP https://github.com/lmcinnes/umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(419327, 512)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = [\"emb_\" + str(i) for i in range(512)]\n",
    "embeddings = df_w2v[columns].values\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 57min 30s, sys: 1min 8s, total: 58min 39s\n",
      "Wall time: 6min 3s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(419327, 5)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "umap_embeddings = umap.UMAP(n_neighbors=15, \n",
    "                            n_components=5, \n",
    "                            metric='cosine').fit_transform(embeddings)\n",
    "umap_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = hdbscan.HDBSCAN(min_cluster_size=15,\n",
    "                          metric='euclidean',                      \n",
    "                          cluster_selection_method='eom').fit(umap_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(419327,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cluster labels\n",
    "labels = cluster.labels_\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clusters: 4297\n"
     ]
    }
   ],
   "source": [
    "#number of clusters (key-words/phrases)\n",
    "print(\"Number of clusters:\",labels.max() + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data for LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### get cluster label as most frequent word/phrase of the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>cluster_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ar art installation</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>st louis</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>passive investment vehicle</td>\n",
       "      <td>3067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nicotinefueled train</td>\n",
       "      <td>2663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>outrageous controversial statement</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 word  cluster_number\n",
       "0                 ar art installation              -1\n",
       "1                            st louis              -1\n",
       "2          passive investment vehicle            3067\n",
       "3                nicotinefueled train            2663\n",
       "4  outrageous controversial statement            2020"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tmp = df_w2v[['word']].copy()\n",
    "df_tmp['cluster_number'] = labels\n",
    "df_tmp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2092379, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>cluster_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rise</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rise</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rise</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rise</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rise</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word  cluster_number\n",
       "0  rise              -1\n",
       "1  rise              -1\n",
       "2  rise              -1\n",
       "3  rise              -1\n",
       "4  rise              -1"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_words = pd.DataFrame({'word': all_NPs + all_Vs})\n",
    "df_all_words = df_all_words.merge(df_tmp, on='word', how='inner')\n",
    "print(df_all_words.shape)\n",
    "df_all_words.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>cluster_number</th>\n",
       "      <th>cluster_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rise</td>\n",
       "      <td>-1</td>\n",
       "      <td>noise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222222</th>\n",
       "      <td>detroit</td>\n",
       "      <td>3330</td>\n",
       "      <td>detroit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444444</th>\n",
       "      <td>president trump</td>\n",
       "      <td>2999</td>\n",
       "      <td>president trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666666</th>\n",
       "      <td>business community</td>\n",
       "      <td>1960</td>\n",
       "      <td>business community</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888888</th>\n",
       "      <td>annual shindig</td>\n",
       "      <td>-1</td>\n",
       "      <td>noise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1111110</th>\n",
       "      <td>short distance</td>\n",
       "      <td>2389</td>\n",
       "      <td>short distance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333332</th>\n",
       "      <td>blue origin ceo bob smith</td>\n",
       "      <td>-1</td>\n",
       "      <td>noise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1555554</th>\n",
       "      <td>direct report</td>\n",
       "      <td>501</td>\n",
       "      <td>direct report</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1777776</th>\n",
       "      <td>needed</td>\n",
       "      <td>3183</td>\n",
       "      <td>needed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999998</th>\n",
       "      <td>monitors</td>\n",
       "      <td>2088</td>\n",
       "      <td>monitors</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              word  cluster_number       cluster_label\n",
       "0                             rise              -1               noise\n",
       "222222                     detroit            3330             detroit\n",
       "444444             president trump            2999     president trump\n",
       "666666          business community            1960  business community\n",
       "888888              annual shindig              -1               noise\n",
       "1111110             short distance            2389      short distance\n",
       "1333332  blue origin ceo bob smith              -1               noise\n",
       "1555554              direct report             501       direct report\n",
       "1777776                     needed            3183              needed\n",
       "1999998                   monitors            2088            monitors"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#label cluster with noise words as \"noise\"\n",
    "def get_label(n,w):\n",
    "    if n == -1:\n",
    "        return \"noise\"\n",
    "    else:\n",
    "        return w\n",
    "\n",
    "df_all_words['cluster_label'] = df_all_words.apply(lambda x: get_label(x.cluster_number, x.word), axis=1) \n",
    "df_all_words.iloc[::222222]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>cluster_number</th>\n",
       "      <th>cluster_label</th>\n",
       "      <th>word_frequency</th>\n",
       "      <th>word_max_frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rise</td>\n",
       "      <td>-1</td>\n",
       "      <td>noise</td>\n",
       "      <td>744651</td>\n",
       "      <td>744651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222222</th>\n",
       "      <td>detroit</td>\n",
       "      <td>3330</td>\n",
       "      <td>detroit</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444444</th>\n",
       "      <td>president trump</td>\n",
       "      <td>2999</td>\n",
       "      <td>president trump</td>\n",
       "      <td>276</td>\n",
       "      <td>850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666666</th>\n",
       "      <td>business community</td>\n",
       "      <td>1960</td>\n",
       "      <td>business community</td>\n",
       "      <td>4</td>\n",
       "      <td>487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888888</th>\n",
       "      <td>annual shindig</td>\n",
       "      <td>-1</td>\n",
       "      <td>noise</td>\n",
       "      <td>744651</td>\n",
       "      <td>744651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1111110</th>\n",
       "      <td>short distance</td>\n",
       "      <td>2389</td>\n",
       "      <td>short distance</td>\n",
       "      <td>6</td>\n",
       "      <td>208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333332</th>\n",
       "      <td>blue origin ceo bob smith</td>\n",
       "      <td>-1</td>\n",
       "      <td>noise</td>\n",
       "      <td>744651</td>\n",
       "      <td>744651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1555554</th>\n",
       "      <td>direct report</td>\n",
       "      <td>501</td>\n",
       "      <td>direct report</td>\n",
       "      <td>3</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1777776</th>\n",
       "      <td>needed</td>\n",
       "      <td>3183</td>\n",
       "      <td>needed</td>\n",
       "      <td>812</td>\n",
       "      <td>2756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999998</th>\n",
       "      <td>monitors</td>\n",
       "      <td>2088</td>\n",
       "      <td>monitors</td>\n",
       "      <td>40</td>\n",
       "      <td>340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              word  cluster_number       cluster_label  \\\n",
       "0                             rise              -1               noise   \n",
       "222222                     detroit            3330             detroit   \n",
       "444444             president trump            2999     president trump   \n",
       "666666          business community            1960  business community   \n",
       "888888              annual shindig              -1               noise   \n",
       "1111110             short distance            2389      short distance   \n",
       "1333332  blue origin ceo bob smith              -1               noise   \n",
       "1555554              direct report             501       direct report   \n",
       "1777776                     needed            3183              needed   \n",
       "1999998                   monitors            2088            monitors   \n",
       "\n",
       "         word_frequency  word_max_frequency  \n",
       "0                744651              744651  \n",
       "222222               85                  85  \n",
       "444444              276                 850  \n",
       "666666                4                 487  \n",
       "888888           744651              744651  \n",
       "1111110               6                 208  \n",
       "1333332          744651              744651  \n",
       "1555554               3                  58  \n",
       "1777776             812                2756  \n",
       "1999998              40                 340  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_words['word_frequency'] = df_all_words.groupby(['cluster_number', \n",
    "                                                       'cluster_label'])['word'].transform(\"count\")\n",
    "df_all_words['word_max_frequency'] = df_all_words.groupby(['cluster_number'])['word_frequency'].transform(\"max\")\n",
    "df_all_words.iloc[::222222]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>1%</th>\n",
       "      <th>10%</th>\n",
       "      <th>20%</th>\n",
       "      <th>30%</th>\n",
       "      <th>40%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>95%</th>\n",
       "      <th>99%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cluster_number</th>\n",
       "      <td>2092379.0</td>\n",
       "      <td>1561.009356</td>\n",
       "      <td>1543.147129</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>381.0</td>\n",
       "      <td>1223.0</td>\n",
       "      <td>2929.0</td>\n",
       "      <td>4211.0</td>\n",
       "      <td>4296.0</td>\n",
       "      <td>4297.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_frequency</th>\n",
       "      <td>2092379.0</td>\n",
       "      <td>265606.304395</td>\n",
       "      <td>356089.683416</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>367.0</td>\n",
       "      <td>861.0</td>\n",
       "      <td>744651.0</td>\n",
       "      <td>744651.0</td>\n",
       "      <td>744651.0</td>\n",
       "      <td>744651.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_max_frequency</th>\n",
       "      <td>2092379.0</td>\n",
       "      <td>265844.972920</td>\n",
       "      <td>355915.140473</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>351.0</td>\n",
       "      <td>622.0</td>\n",
       "      <td>1211.0</td>\n",
       "      <td>744651.0</td>\n",
       "      <td>744651.0</td>\n",
       "      <td>744651.0</td>\n",
       "      <td>744651.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        count           mean            std  min   1%   10%  \\\n",
       "cluster_number      2092379.0    1561.009356    1543.147129 -1.0 -1.0  -1.0   \n",
       "word_frequency      2092379.0  265606.304395  356089.683416  1.0  1.0   2.0   \n",
       "word_max_frequency  2092379.0  265844.972920  355915.140473  1.0  8.0  62.0   \n",
       "\n",
       "                      20%    30%    40%     50%       75%       95%       99%  \\\n",
       "cluster_number       -1.0   -1.0  381.0  1223.0    2929.0    4211.0    4296.0   \n",
       "word_frequency       23.0  123.0  367.0   861.0  744651.0  744651.0  744651.0   \n",
       "word_max_frequency  163.0  351.0  622.0  1211.0  744651.0  744651.0  744651.0   \n",
       "\n",
       "                         max  \n",
       "cluster_number        4297.0  \n",
       "word_frequency      744651.0  \n",
       "word_max_frequency  744651.0  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(df_all_words.describe(percentiles=[0.01,0.1,0.20,0.3,0.4,0.5,0.75,0.95,0.99])).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "744734 1347645\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>cluster_number</th>\n",
       "      <th>cluster_label</th>\n",
       "      <th>word_frequency</th>\n",
       "      <th>word_max_frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rise</td>\n",
       "      <td>-1</td>\n",
       "      <td>noise</td>\n",
       "      <td>744651</td>\n",
       "      <td>744651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rise</td>\n",
       "      <td>-1</td>\n",
       "      <td>noise</td>\n",
       "      <td>744651</td>\n",
       "      <td>744651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rise</td>\n",
       "      <td>-1</td>\n",
       "      <td>noise</td>\n",
       "      <td>744651</td>\n",
       "      <td>744651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rise</td>\n",
       "      <td>-1</td>\n",
       "      <td>noise</td>\n",
       "      <td>744651</td>\n",
       "      <td>744651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rise</td>\n",
       "      <td>-1</td>\n",
       "      <td>noise</td>\n",
       "      <td>744651</td>\n",
       "      <td>744651</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word  cluster_number cluster_label  word_frequency  word_max_frequency\n",
       "0  rise              -1         noise          744651              744651\n",
       "1  rise              -1         noise          744651              744651\n",
       "2  rise              -1         noise          744651              744651\n",
       "3  rise              -1         noise          744651              744651\n",
       "4  rise              -1         noise          744651              744651"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_words['word_max_frequency'] = df_all_words.groupby(['cluster_number'])['word_frequency'].transform(\"max\")\n",
    "\n",
    "df_tmp_noise = pd.DataFrame(df_all_words[df_all_words['cluster_label'] == \"noise\"])\n",
    "df_tmp_other = df_all_words[df_all_words['cluster_label'] != \"noise\"]\n",
    "print(len(df_tmp_noise),len(df_tmp_other))\n",
    "df_noise.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4298, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster_number</th>\n",
       "      <th>cluster_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>gopro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>1000</td>\n",
       "      <td>data center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>2000</td>\n",
       "      <td>nazis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000</th>\n",
       "      <td>3000</td>\n",
       "      <td>earnings report</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4000</th>\n",
       "      <td>4000</td>\n",
       "      <td>point</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      cluster_number    cluster_label\n",
       "0                  0            gopro\n",
       "1000            1000      data center\n",
       "2000            2000            nazis\n",
       "3000            3000  earnings report\n",
       "4000            4000            point"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tmp = df_tmp_other[df_tmp_other['word_max_frequency'] == df_tmp_other['word_frequency']]\n",
    "df_tmp = df_tmp.groupby('cluster_number')['cluster_label'].last().reset_index()\n",
    "print(df_tmp.shape)\n",
    "df_tmp.iloc[::1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2092379, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>222222</th>\n",
       "      <th>444444</th>\n",
       "      <th>666666</th>\n",
       "      <th>888888</th>\n",
       "      <th>1111110</th>\n",
       "      <th>1333332</th>\n",
       "      <th>1555554</th>\n",
       "      <th>1777776</th>\n",
       "      <th>1999998</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <td>rise</td>\n",
       "      <td>detroit</td>\n",
       "      <td>president trump</td>\n",
       "      <td>business community</td>\n",
       "      <td>annual shindig</td>\n",
       "      <td>short distance</td>\n",
       "      <td>blue origin ceo bob smith</td>\n",
       "      <td>direct report</td>\n",
       "      <td>needed</td>\n",
       "      <td>monitors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster_number</th>\n",
       "      <td>-1</td>\n",
       "      <td>3330</td>\n",
       "      <td>2999</td>\n",
       "      <td>1960</td>\n",
       "      <td>-1</td>\n",
       "      <td>2389</td>\n",
       "      <td>-1</td>\n",
       "      <td>501</td>\n",
       "      <td>3183</td>\n",
       "      <td>2088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster_label</th>\n",
       "      <td>noise</td>\n",
       "      <td>detroit</td>\n",
       "      <td>trump</td>\n",
       "      <td>community</td>\n",
       "      <td>noise</td>\n",
       "      <td>distance</td>\n",
       "      <td>noise</td>\n",
       "      <td>direct</td>\n",
       "      <td>need</td>\n",
       "      <td>monitor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0        222222           444444              666666   \\\n",
       "word              rise  detroit  president trump  business community   \n",
       "cluster_number      -1     3330             2999                1960   \n",
       "cluster_label    noise  detroit            trump           community   \n",
       "\n",
       "                       888888          1111110                    1333332  \\\n",
       "word            annual shindig  short distance  blue origin ceo bob smith   \n",
       "cluster_number              -1            2389                         -1   \n",
       "cluster_label            noise        distance                      noise   \n",
       "\n",
       "                      1555554 1777776   1999998  \n",
       "word            direct report  needed  monitors  \n",
       "cluster_number            501    3183      2088  \n",
       "cluster_label          direct    need   monitor  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_word_clusters = df_all_words[['word', 'cluster_number']]\n",
    "df_word_clusters = df_word_clusters.merge(df_tmp, on='cluster_number', how='left')\n",
    "\n",
    "df_word_clusters['cluster_label'] = df_word_clusters['cluster_label'].fillna(\"noise\")\n",
    "\n",
    "print(df_word_clusters.shape)\n",
    "df_word_clusters.iloc[::222222].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "419327\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster_label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rise</th>\n",
       "      <td>noise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>big emerging economy</th>\n",
       "      <td>economy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>china</th>\n",
       "      <td>noise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>india</th>\n",
       "      <td>noise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>steady march</th>\n",
       "      <td>noise</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     cluster_label\n",
       "word                              \n",
       "rise                         noise\n",
       "big emerging economy       economy\n",
       "china                        noise\n",
       "india                        noise\n",
       "steady march                 noise"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create word -> cluster_name series\n",
    "del df_word_clusters['cluster_number']\n",
    "df_word_clusters = df_word_clusters.drop_duplicates()\n",
    "\n",
    "word_cluster_label = df_word_clusters.set_index(\"word\")\n",
    "print(len(word_cluster_label))\n",
    "word_cluster_label.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next:\n",
    "- replacing texts with list of key-words\n",
    "- running LDA\n",
    "\n",
    "\n",
    "https://towardsdatascience.com/topic-modeling-with-bert-779f7db187e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "GLG - 3_step - Assigning Text Groups.ipynb",
   "toc_visible": true,
   "version": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "305.455px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
