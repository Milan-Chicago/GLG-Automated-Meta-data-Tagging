{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Idea:\n",
    "Our solution: LDA + BERT based embeddings of noun phrases and verbs :\n",
    "- Each noun phrase and verb in the texts is  transformed to embedding vector using Universal Sentence Encoder (transformer based on BERT)\n",
    "- Embedding vectors from (a) are clustered (HDBSCAN + UNET)\n",
    "- Words/phrases with embedding vectors closest to the centers of resulting clusters form key word/phrase\n",
    "- Each text in the training sample is converted to collection of key-phrases by replacing its noun phrases and verbs with keyword/phrases and deleting other words\n",
    "- LDA is performed on the transformed texts\n",
    "\n",
    "\n",
    "**Reference:**<br>\n",
    "Daniel Cer, Yinfei Yang, Sheng-yi Kong, Nan Hua, Nicole Limtiaco, Rhomni St. John, Noah Constant, Mario Guajardo-CÃ©spedes, Steve Yuan, Chris Tar, Yun-Hsuan Sung, Brian Strope, Ray Kurzweil. **Universal Sentence Encoder.** *arXiv:1803.11175, 2018.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "clNUUp3MUO2t"
   },
   "source": [
    "# Load data and python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1622131163361,
     "user": {
      "displayName": "Tatiana Chebonenko",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgwGu7u_TizJ74HmaMD0AtIfiksMdhRYrfZtevXzQ=s64",
      "userId": "10264586744881678851"
     },
     "user_tz": 240
    },
    "id": "7dYQIbH6UO2u"
   },
   "outputs": [],
   "source": [
    "# data processing libraries\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "# display wider columns in pandas data frames where necessary\n",
    "pd.set_option('max_colwidth',150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2097,
     "status": "ok",
     "timestamp": 1622131165457,
     "user": {
      "displayName": "Tatiana Chebonenko",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgwGu7u_TizJ74HmaMD0AtIfiksMdhRYrfZtevXzQ=s64",
      "userId": "10264586744881678851"
     },
     "user_tz": 240
    },
    "id": "wBbgkDdQWoC7",
    "outputId": "f81ca11e-eb74-43b2-80c9-db2540a3986c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.2.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15713,
     "status": "ok",
     "timestamp": 1622131181167,
     "user": {
      "displayName": "Tatiana Chebonenko",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgwGu7u_TizJ74HmaMD0AtIfiksMdhRYrfZtevXzQ=s64",
      "userId": "10264586744881678851"
     },
     "user_tz": 240
    },
    "id": "ySqw1ZsjWpwt",
    "outputId": "73e0189f-ba4f-43fb-f34b-cc43f657f428"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module https://tfhub.dev/google/universal-sentence-encoder-large/5 loaded\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_hub as hub\n",
    "\n",
    "#Load the Universal Sentence Encoder's TF Hub module\n",
    "module_url = \"https://tfhub.dev/google/universal-sentence-encoder-large/5\"\n",
    "model = hub.load(module_url)\n",
    "\n",
    "print (\"module %s loaded\" % module_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train.shape: (33982, 12)\n",
      "df_train.shape: Index(['date', 'author', 'title', 'url', 'section', 'publication',\n",
      "       'first_10_sents', 'list_of_first_10_sents', 'list_of_verb_lemmas',\n",
      "       'noun_phrases', 'list_of_nouns', 'list_of_lemmas'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"./transition_files/train.tsv\", sep='\\t')\n",
    "print(\"df_train.shape:\", df_train.shape)\n",
    "print(\"df_train.shape:\",df_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Bxk10XYUqNp"
   },
   "source": [
    "# Getting text clusters through sentence embedding comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1622131190534,
     "user": {
      "displayName": "Tatiana Chebonenko",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgwGu7u_TizJ74HmaMD0AtIfiksMdhRYrfZtevXzQ=s64",
      "userId": "10264586744881678851"
     },
     "user_tz": 240
    },
    "id": "MsgF9abaX2Bn"
   },
   "outputs": [],
   "source": [
    "def get_embeddings(input):\n",
    "    return model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_embeddings(df_data, column = \"word\", N_batches=1):\n",
    "    #split data into N batches\n",
    "    N = N_batches\n",
    "\n",
    "    part = int(len(df_data)/N)\n",
    "    print(N, \"batches with\", part + 1, column + \"s each\")\n",
    "\n",
    "    #get embeddings for each N words\n",
    "    index = 0\n",
    "    batch_num = 0\n",
    "    list_dfs = []\n",
    "\n",
    "    while index < len(df_data): \n",
    "        df_tmp = df_data.iloc[index : index + part].copy()\n",
    "        df_tmp = df_tmp.reset_index(drop=True)\n",
    "        print (\"Batch number:\", batch_num + 1, \"out of \", N)\n",
    "\n",
    "        df_batch_embeddings = pd.DataFrame(get_embeddings(list(df_tmp[column])).numpy())\n",
    "\n",
    "        num_embeddings = df_batch_embeddings.shape[1]\n",
    "        columns = [\"emb_\" + str(i) for i in range(512)]\n",
    "        df_tmp[columns] = df_batch_embeddings\n",
    "\n",
    "        list_dfs.append(df_tmp)\n",
    "        batch_num = batch_num + 1\n",
    "        index = index + part\n",
    "\n",
    "    #concatinate batches into single dataset\n",
    "    df_emb = pd.concat(list_dfs)\n",
    "\n",
    "    return df_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [rise, big emerging economy, china, india, steady march, globalisation, surge, number, people, business, tourism, result, demand, visa, unpreceden...\n",
       "1    [pfizer, commitment, corporate social responsibility csr, drugs giant talk, responsibility, society, world, access, product, work, ngos, global he...\n",
       "2    [week, federal reserve, interest rate, time, year, world, central bank, rate, recent year, long spell, course, chart, outcome, americas rate rise,...\n",
       "3    [cruise line, wave, year, nearly, holiday, sea, result, december 18th carnival, worlds largest operator, global market, fullyear earning, demand, ...\n",
       "4    [investors, calendar year, buoyant mood, unexpected event, consensus, respect, view, investor, market price, column, potential surprise, definitio...\n",
       "Name: noun_phrases, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['noun_phrases'] = df_train['noun_phrases'].str[2:-2]\n",
    "df_train['noun_phrases'] = df_train['noun_phrases'].str.lower().str.split(\"', '\")\n",
    "df_train['noun_phrases'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['rise', 'big emerging economy', 'china', 'india', 'steady march'], 1417049)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_NPs = list(df_train['noun_phrases'])\n",
    "all_NPs = [np for l in all_NPs for np in l if len(np)>0]\n",
    "all_NPs[:5], len(all_NPs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[emerging, led, wanting, travel, granted, Upgrade, travel, apply, submit, streamline, scrap]'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['list_of_verb_lemmas'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                               [merging, led, wanting, travel, granted, upgrade, travel, apply, submit, streamline, scra]\n",
       "1    [rided, embracing, insists, gain, strengthen, improve, deterred, seeking, intends, shift, domiciled, rejoiced, saved, paid, outraged, promised, im...\n",
       "2    [aised, ended, celebrate, tried, lift, forced, reverse, cut, help, understand, upgrade, strike, wish, save, spend, try, escape, slashing, encourag...\n",
       "3      [race, booked, improve, announced, control, demand, peaking, piling, based, got, moving, upgrade, increase, announced, establish, aimed, based, ad]\n",
       "4    [tart, caught, proved, reflected, like, suggest, judged, betting, expect, upgrade, weakens, having, pushed, tighten, buy, priced, doubt, tighten, ...\n",
       "Name: list_of_verb_lemmas, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['list_of_verb_lemmas'] = df_train['list_of_verb_lemmas'].str[2:-2]\n",
    "df_train['list_of_verb_lemmas'] = df_train['list_of_verb_lemmas'].str.lower().str.split(\", \")\n",
    "df_train['list_of_verb_lemmas'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['merging', 'led', 'wanting', 'travel', 'granted'], 675330)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_Vs = list(df_train['list_of_verb_lemmas'])\n",
    "all_Vs = [v for l in all_Vs for v in l if len(v)>0]\n",
    "all_Vs[:5], len(all_Vs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "419327"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words =  list(set(all_NPs + all_Vs))\n",
    "len(set(all_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "0_QElB-4UM2z",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rival fortnite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>potentially shameinducing data point</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>largest recorded leak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>voracious reader</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>perfect pendular motion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   word\n",
       "0                        rival fortnite\n",
       "1  potentially shameinducing data point\n",
       "2                 largest recorded leak\n",
       "3                      voracious reader\n",
       "4               perfect pendular motion"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_words = pd.DataFrame({'word': all_words})\n",
    "df_words.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 batches with 4194 words each\n",
      "Batch number: 1 out of  100\n",
      "Batch number: 2 out of  100\n",
      "Batch number: 3 out of  100\n",
      "Batch number: 4 out of  100\n",
      "Batch number: 5 out of  100\n",
      "Batch number: 6 out of  100\n",
      "Batch number: 7 out of  100\n",
      "Batch number: 8 out of  100\n",
      "Batch number: 9 out of  100\n",
      "Batch number: 10 out of  100\n",
      "Batch number: 11 out of  100\n",
      "Batch number: 12 out of  100\n",
      "Batch number: 13 out of  100\n",
      "Batch number: 14 out of  100\n",
      "Batch number: 15 out of  100\n",
      "Batch number: 16 out of  100\n",
      "Batch number: 17 out of  100\n",
      "Batch number: 18 out of  100\n",
      "Batch number: 19 out of  100\n",
      "Batch number: 20 out of  100\n",
      "Batch number: 21 out of  100\n",
      "Batch number: 22 out of  100\n",
      "Batch number: 23 out of  100\n",
      "Batch number: 24 out of  100\n",
      "Batch number: 25 out of  100\n",
      "Batch number: 26 out of  100\n",
      "Batch number: 27 out of  100\n",
      "Batch number: 28 out of  100\n",
      "Batch number: 29 out of  100\n",
      "Batch number: 30 out of  100\n",
      "Batch number: 31 out of  100\n",
      "Batch number: 32 out of  100\n",
      "Batch number: 33 out of  100\n",
      "Batch number: 34 out of  100\n",
      "Batch number: 35 out of  100\n",
      "Batch number: 36 out of  100\n",
      "Batch number: 37 out of  100\n",
      "Batch number: 38 out of  100\n",
      "Batch number: 39 out of  100\n",
      "Batch number: 40 out of  100\n",
      "Batch number: 41 out of  100\n",
      "Batch number: 42 out of  100\n",
      "Batch number: 43 out of  100\n",
      "Batch number: 44 out of  100\n",
      "Batch number: 45 out of  100\n",
      "Batch number: 46 out of  100\n",
      "Batch number: 47 out of  100\n",
      "Batch number: 48 out of  100\n",
      "Batch number: 49 out of  100\n",
      "Batch number: 50 out of  100\n",
      "Batch number: 51 out of  100\n",
      "Batch number: 52 out of  100\n",
      "Batch number: 53 out of  100\n",
      "Batch number: 54 out of  100\n",
      "Batch number: 55 out of  100\n",
      "Batch number: 56 out of  100\n",
      "Batch number: 57 out of  100\n",
      "Batch number: 58 out of  100\n",
      "Batch number: 59 out of  100\n",
      "Batch number: 60 out of  100\n",
      "Batch number: 61 out of  100\n",
      "Batch number: 62 out of  100\n",
      "Batch number: 63 out of  100\n",
      "Batch number: 64 out of  100\n",
      "Batch number: 65 out of  100\n",
      "Batch number: 66 out of  100\n",
      "Batch number: 67 out of  100\n",
      "Batch number: 68 out of  100\n",
      "Batch number: 69 out of  100\n",
      "Batch number: 70 out of  100\n",
      "Batch number: 71 out of  100\n",
      "Batch number: 72 out of  100\n",
      "Batch number: 73 out of  100\n",
      "Batch number: 74 out of  100\n",
      "Batch number: 75 out of  100\n",
      "Batch number: 76 out of  100\n",
      "Batch number: 77 out of  100\n",
      "Batch number: 78 out of  100\n",
      "Batch number: 79 out of  100\n",
      "Batch number: 80 out of  100\n",
      "Batch number: 81 out of  100\n",
      "Batch number: 82 out of  100\n",
      "Batch number: 83 out of  100\n",
      "Batch number: 84 out of  100\n",
      "Batch number: 85 out of  100\n",
      "Batch number: 86 out of  100\n",
      "Batch number: 87 out of  100\n",
      "Batch number: 88 out of  100\n",
      "Batch number: 89 out of  100\n",
      "Batch number: 90 out of  100\n",
      "Batch number: 91 out of  100\n",
      "Batch number: 92 out of  100\n",
      "Batch number: 93 out of  100\n",
      "Batch number: 94 out of  100\n",
      "Batch number: 95 out of  100\n",
      "Batch number: 96 out of  100\n",
      "Batch number: 97 out of  100\n",
      "Batch number: 98 out of  100\n",
      "Batch number: 99 out of  100\n",
      "Batch number: 100 out of  100\n",
      "Batch number: 101 out of  100\n",
      "CPU times: user 50min 22s, sys: 2min 19s, total: 52min 42s\n",
      "Wall time: 5min 23s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>emb_0</th>\n",
       "      <th>emb_1</th>\n",
       "      <th>emb_2</th>\n",
       "      <th>emb_3</th>\n",
       "      <th>emb_4</th>\n",
       "      <th>emb_5</th>\n",
       "      <th>emb_6</th>\n",
       "      <th>emb_7</th>\n",
       "      <th>emb_8</th>\n",
       "      <th>...</th>\n",
       "      <th>emb_502</th>\n",
       "      <th>emb_503</th>\n",
       "      <th>emb_504</th>\n",
       "      <th>emb_505</th>\n",
       "      <th>emb_506</th>\n",
       "      <th>emb_507</th>\n",
       "      <th>emb_508</th>\n",
       "      <th>emb_509</th>\n",
       "      <th>emb_510</th>\n",
       "      <th>emb_511</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rival fortnite</td>\n",
       "      <td>-0.028948</td>\n",
       "      <td>0.064054</td>\n",
       "      <td>0.014190</td>\n",
       "      <td>0.073210</td>\n",
       "      <td>-0.088359</td>\n",
       "      <td>0.110766</td>\n",
       "      <td>0.077670</td>\n",
       "      <td>0.035829</td>\n",
       "      <td>-0.032533</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.042242</td>\n",
       "      <td>-0.030448</td>\n",
       "      <td>-0.030571</td>\n",
       "      <td>-0.032998</td>\n",
       "      <td>0.034555</td>\n",
       "      <td>0.113697</td>\n",
       "      <td>0.018538</td>\n",
       "      <td>0.038067</td>\n",
       "      <td>-0.000274</td>\n",
       "      <td>0.024339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>potentially shameinducing data point</td>\n",
       "      <td>0.021808</td>\n",
       "      <td>-0.037296</td>\n",
       "      <td>-0.005880</td>\n",
       "      <td>0.041247</td>\n",
       "      <td>0.018105</td>\n",
       "      <td>-0.053182</td>\n",
       "      <td>-0.016855</td>\n",
       "      <td>0.056972</td>\n",
       "      <td>-0.046322</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033671</td>\n",
       "      <td>0.052779</td>\n",
       "      <td>-0.049987</td>\n",
       "      <td>-0.060884</td>\n",
       "      <td>-0.043943</td>\n",
       "      <td>0.062954</td>\n",
       "      <td>0.008635</td>\n",
       "      <td>0.013899</td>\n",
       "      <td>-0.009536</td>\n",
       "      <td>-0.042446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>largest recorded leak</td>\n",
       "      <td>0.021657</td>\n",
       "      <td>0.065861</td>\n",
       "      <td>0.025957</td>\n",
       "      <td>0.004588</td>\n",
       "      <td>-0.074570</td>\n",
       "      <td>-0.005124</td>\n",
       "      <td>0.038522</td>\n",
       "      <td>-0.015959</td>\n",
       "      <td>-0.038741</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.038165</td>\n",
       "      <td>0.023003</td>\n",
       "      <td>-0.037180</td>\n",
       "      <td>-0.007455</td>\n",
       "      <td>-0.026193</td>\n",
       "      <td>0.066191</td>\n",
       "      <td>-0.115580</td>\n",
       "      <td>0.048890</td>\n",
       "      <td>0.070551</td>\n",
       "      <td>0.033378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>voracious reader</td>\n",
       "      <td>0.068322</td>\n",
       "      <td>-0.005061</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000334</td>\n",
       "      <td>0.007211</td>\n",
       "      <td>-0.036811</td>\n",
       "      <td>0.044334</td>\n",
       "      <td>0.021194</td>\n",
       "      <td>0.008174</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006287</td>\n",
       "      <td>0.035995</td>\n",
       "      <td>-0.044218</td>\n",
       "      <td>-0.004517</td>\n",
       "      <td>0.006305</td>\n",
       "      <td>0.001964</td>\n",
       "      <td>-0.029977</td>\n",
       "      <td>-0.027318</td>\n",
       "      <td>0.015790</td>\n",
       "      <td>-0.007895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>perfect pendular motion</td>\n",
       "      <td>0.020700</td>\n",
       "      <td>-0.016234</td>\n",
       "      <td>0.029166</td>\n",
       "      <td>0.038285</td>\n",
       "      <td>0.013007</td>\n",
       "      <td>-0.013796</td>\n",
       "      <td>0.030645</td>\n",
       "      <td>-0.022268</td>\n",
       "      <td>0.110818</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023359</td>\n",
       "      <td>-0.040579</td>\n",
       "      <td>-0.006551</td>\n",
       "      <td>-0.035399</td>\n",
       "      <td>0.013381</td>\n",
       "      <td>-0.003827</td>\n",
       "      <td>-0.056309</td>\n",
       "      <td>0.024389</td>\n",
       "      <td>0.005806</td>\n",
       "      <td>0.035837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã 513 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   word     emb_0     emb_1     emb_2  \\\n",
       "0                        rival fortnite -0.028948  0.064054  0.014190   \n",
       "1  potentially shameinducing data point  0.021808 -0.037296 -0.005880   \n",
       "2                 largest recorded leak  0.021657  0.065861  0.025957   \n",
       "3                      voracious reader  0.068322 -0.005061  0.000025   \n",
       "4               perfect pendular motion  0.020700 -0.016234  0.029166   \n",
       "\n",
       "      emb_3     emb_4     emb_5     emb_6     emb_7     emb_8  ...   emb_502  \\\n",
       "0  0.073210 -0.088359  0.110766  0.077670  0.035829 -0.032533  ... -0.042242   \n",
       "1  0.041247  0.018105 -0.053182 -0.016855  0.056972 -0.046322  ... -0.033671   \n",
       "2  0.004588 -0.074570 -0.005124  0.038522 -0.015959 -0.038741  ... -0.038165   \n",
       "3  0.000334  0.007211 -0.036811  0.044334  0.021194  0.008174  ...  0.006287   \n",
       "4  0.038285  0.013007 -0.013796  0.030645 -0.022268  0.110818  ...  0.023359   \n",
       "\n",
       "    emb_503   emb_504   emb_505   emb_506   emb_507   emb_508   emb_509  \\\n",
       "0 -0.030448 -0.030571 -0.032998  0.034555  0.113697  0.018538  0.038067   \n",
       "1  0.052779 -0.049987 -0.060884 -0.043943  0.062954  0.008635  0.013899   \n",
       "2  0.023003 -0.037180 -0.007455 -0.026193  0.066191 -0.115580  0.048890   \n",
       "3  0.035995 -0.044218 -0.004517  0.006305  0.001964 -0.029977 -0.027318   \n",
       "4 -0.040579 -0.006551 -0.035399  0.013381 -0.003827 -0.056309  0.024389   \n",
       "\n",
       "    emb_510   emb_511  \n",
       "0 -0.000274  0.024339  \n",
       "1 -0.009536 -0.042446  \n",
       "2  0.070551  0.033378  \n",
       "3  0.015790 -0.007895  \n",
       "4  0.005806  0.035837  \n",
       "\n",
       "[5 rows x 513 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#creating word2vec matrix\n",
    "df_w2v = get_word_embeddings(df_words, column = \"word\", N_batches=100)\n",
    "df_w2v.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>emb_0</th>\n",
       "      <th>emb_1</th>\n",
       "      <th>emb_2</th>\n",
       "      <th>emb_3</th>\n",
       "      <th>emb_4</th>\n",
       "      <th>emb_5</th>\n",
       "      <th>emb_6</th>\n",
       "      <th>emb_7</th>\n",
       "      <th>emb_8</th>\n",
       "      <th>...</th>\n",
       "      <th>emb_502</th>\n",
       "      <th>emb_503</th>\n",
       "      <th>emb_504</th>\n",
       "      <th>emb_505</th>\n",
       "      <th>emb_506</th>\n",
       "      <th>emb_507</th>\n",
       "      <th>emb_508</th>\n",
       "      <th>emb_509</th>\n",
       "      <th>emb_510</th>\n",
       "      <th>emb_511</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rival fortnite</td>\n",
       "      <td>-0.028948</td>\n",
       "      <td>0.064054</td>\n",
       "      <td>0.014190</td>\n",
       "      <td>0.073210</td>\n",
       "      <td>-0.088359</td>\n",
       "      <td>0.110766</td>\n",
       "      <td>0.077670</td>\n",
       "      <td>0.035829</td>\n",
       "      <td>-0.032533</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.042242</td>\n",
       "      <td>-0.030448</td>\n",
       "      <td>-0.030571</td>\n",
       "      <td>-0.032998</td>\n",
       "      <td>0.034555</td>\n",
       "      <td>0.113697</td>\n",
       "      <td>0.018538</td>\n",
       "      <td>0.038067</td>\n",
       "      <td>-0.000274</td>\n",
       "      <td>0.024339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2421</th>\n",
       "      <td>philip morris internationals</td>\n",
       "      <td>0.071751</td>\n",
       "      <td>0.058493</td>\n",
       "      <td>-0.002705</td>\n",
       "      <td>0.040606</td>\n",
       "      <td>-0.022526</td>\n",
       "      <td>0.081023</td>\n",
       "      <td>-0.014479</td>\n",
       "      <td>0.043452</td>\n",
       "      <td>-0.051692</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035390</td>\n",
       "      <td>-0.051603</td>\n",
       "      <td>-0.014338</td>\n",
       "      <td>-0.007827</td>\n",
       "      <td>0.075689</td>\n",
       "      <td>0.006039</td>\n",
       "      <td>-0.022070</td>\n",
       "      <td>-0.014119</td>\n",
       "      <td>0.066530</td>\n",
       "      <td>0.036217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>unplugged</td>\n",
       "      <td>-0.044945</td>\n",
       "      <td>0.019505</td>\n",
       "      <td>0.042838</td>\n",
       "      <td>-0.024796</td>\n",
       "      <td>-0.085768</td>\n",
       "      <td>-0.033376</td>\n",
       "      <td>0.019646</td>\n",
       "      <td>0.065180</td>\n",
       "      <td>-0.061526</td>\n",
       "      <td>...</td>\n",
       "      <td>0.072080</td>\n",
       "      <td>0.064702</td>\n",
       "      <td>-0.025158</td>\n",
       "      <td>-0.011246</td>\n",
       "      <td>-0.058174</td>\n",
       "      <td>-0.105868</td>\n",
       "      <td>0.006102</td>\n",
       "      <td>-0.044000</td>\n",
       "      <td>-0.010283</td>\n",
       "      <td>-0.025208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3070</th>\n",
       "      <td>annual meeting</td>\n",
       "      <td>-0.083934</td>\n",
       "      <td>-0.006209</td>\n",
       "      <td>-0.011543</td>\n",
       "      <td>-0.071184</td>\n",
       "      <td>0.041844</td>\n",
       "      <td>0.046135</td>\n",
       "      <td>-0.012820</td>\n",
       "      <td>-0.112799</td>\n",
       "      <td>0.030378</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026774</td>\n",
       "      <td>0.015173</td>\n",
       "      <td>0.041242</td>\n",
       "      <td>0.017139</td>\n",
       "      <td>0.021064</td>\n",
       "      <td>0.052726</td>\n",
       "      <td>0.011243</td>\n",
       "      <td>0.062688</td>\n",
       "      <td>0.013496</td>\n",
       "      <td>-0.055573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1298</th>\n",
       "      <td>rigidly enforced gender expectation</td>\n",
       "      <td>-0.020639</td>\n",
       "      <td>0.051757</td>\n",
       "      <td>-0.024310</td>\n",
       "      <td>-0.052477</td>\n",
       "      <td>0.064120</td>\n",
       "      <td>-0.079127</td>\n",
       "      <td>-0.069198</td>\n",
       "      <td>0.018345</td>\n",
       "      <td>-0.065469</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068233</td>\n",
       "      <td>0.042767</td>\n",
       "      <td>-0.023927</td>\n",
       "      <td>-0.012723</td>\n",
       "      <td>-0.028446</td>\n",
       "      <td>0.042471</td>\n",
       "      <td>-0.007701</td>\n",
       "      <td>-0.015071</td>\n",
       "      <td>0.005724</td>\n",
       "      <td>-0.003037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3719</th>\n",
       "      <td>postpothole repair</td>\n",
       "      <td>0.007223</td>\n",
       "      <td>-0.036479</td>\n",
       "      <td>-0.012374</td>\n",
       "      <td>0.029721</td>\n",
       "      <td>-0.004580</td>\n",
       "      <td>-0.002598</td>\n",
       "      <td>-0.000942</td>\n",
       "      <td>0.003334</td>\n",
       "      <td>-0.040680</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033686</td>\n",
       "      <td>-0.029744</td>\n",
       "      <td>0.007175</td>\n",
       "      <td>-0.008106</td>\n",
       "      <td>-0.031989</td>\n",
       "      <td>0.044643</td>\n",
       "      <td>-0.019443</td>\n",
       "      <td>-0.005706</td>\n",
       "      <td>-0.006232</td>\n",
       "      <td>0.067022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1947</th>\n",
       "      <td>republican senator jon kyl</td>\n",
       "      <td>-0.074448</td>\n",
       "      <td>0.017038</td>\n",
       "      <td>-0.037902</td>\n",
       "      <td>-0.011970</td>\n",
       "      <td>0.002294</td>\n",
       "      <td>0.048126</td>\n",
       "      <td>-0.020591</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>-0.027261</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.036317</td>\n",
       "      <td>-0.027186</td>\n",
       "      <td>0.125992</td>\n",
       "      <td>0.015419</td>\n",
       "      <td>-0.039449</td>\n",
       "      <td>0.055503</td>\n",
       "      <td>-0.024551</td>\n",
       "      <td>0.076030</td>\n",
       "      <td>-0.022705</td>\n",
       "      <td>-0.019698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>magdalena zernickagoetz</td>\n",
       "      <td>0.004264</td>\n",
       "      <td>0.018595</td>\n",
       "      <td>0.012869</td>\n",
       "      <td>0.032346</td>\n",
       "      <td>0.016008</td>\n",
       "      <td>0.017975</td>\n",
       "      <td>0.048702</td>\n",
       "      <td>-0.011801</td>\n",
       "      <td>-0.042248</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007407</td>\n",
       "      <td>-0.020057</td>\n",
       "      <td>-0.000438</td>\n",
       "      <td>0.023585</td>\n",
       "      <td>-0.046515</td>\n",
       "      <td>0.003248</td>\n",
       "      <td>0.001250</td>\n",
       "      <td>0.018682</td>\n",
       "      <td>-0.015019</td>\n",
       "      <td>0.022444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2596</th>\n",
       "      <td>nearly 2bn</td>\n",
       "      <td>-0.035940</td>\n",
       "      <td>0.005396</td>\n",
       "      <td>-0.032637</td>\n",
       "      <td>0.071618</td>\n",
       "      <td>-0.031461</td>\n",
       "      <td>0.046243</td>\n",
       "      <td>-0.011780</td>\n",
       "      <td>0.033512</td>\n",
       "      <td>0.061371</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.065193</td>\n",
       "      <td>-0.060827</td>\n",
       "      <td>-0.003603</td>\n",
       "      <td>0.006782</td>\n",
       "      <td>-0.003571</td>\n",
       "      <td>0.047496</td>\n",
       "      <td>-0.034156</td>\n",
       "      <td>0.002539</td>\n",
       "      <td>0.012971</td>\n",
       "      <td>0.039395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>border angola</td>\n",
       "      <td>-0.016436</td>\n",
       "      <td>0.029175</td>\n",
       "      <td>-0.115872</td>\n",
       "      <td>-0.052781</td>\n",
       "      <td>0.047338</td>\n",
       "      <td>-0.025110</td>\n",
       "      <td>-0.045445</td>\n",
       "      <td>0.012612</td>\n",
       "      <td>-0.048793</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010449</td>\n",
       "      <td>-0.112085</td>\n",
       "      <td>0.114980</td>\n",
       "      <td>-0.005818</td>\n",
       "      <td>-0.031272</td>\n",
       "      <td>0.061169</td>\n",
       "      <td>0.032391</td>\n",
       "      <td>0.069337</td>\n",
       "      <td>-0.006547</td>\n",
       "      <td>-0.051745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3245</th>\n",
       "      <td>bus campaign</td>\n",
       "      <td>-0.090365</td>\n",
       "      <td>-0.011007</td>\n",
       "      <td>-0.026151</td>\n",
       "      <td>-0.059735</td>\n",
       "      <td>-0.013370</td>\n",
       "      <td>0.014698</td>\n",
       "      <td>-0.063526</td>\n",
       "      <td>-0.021808</td>\n",
       "      <td>0.033240</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.049083</td>\n",
       "      <td>-0.004245</td>\n",
       "      <td>0.046844</td>\n",
       "      <td>-0.016459</td>\n",
       "      <td>-0.017473</td>\n",
       "      <td>-0.011006</td>\n",
       "      <td>-0.011537</td>\n",
       "      <td>0.060725</td>\n",
       "      <td>-0.000908</td>\n",
       "      <td>-0.027614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1473</th>\n",
       "      <td>simpleton roombas</td>\n",
       "      <td>0.046562</td>\n",
       "      <td>-0.003330</td>\n",
       "      <td>0.049606</td>\n",
       "      <td>0.009292</td>\n",
       "      <td>0.033348</td>\n",
       "      <td>-0.046104</td>\n",
       "      <td>0.074190</td>\n",
       "      <td>0.035382</td>\n",
       "      <td>0.002309</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012698</td>\n",
       "      <td>0.031249</td>\n",
       "      <td>-0.044579</td>\n",
       "      <td>-0.027117</td>\n",
       "      <td>-0.005787</td>\n",
       "      <td>0.041612</td>\n",
       "      <td>-0.015210</td>\n",
       "      <td>0.046340</td>\n",
       "      <td>0.005281</td>\n",
       "      <td>-0.093688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3894</th>\n",
       "      <td>vast complex</td>\n",
       "      <td>0.027698</td>\n",
       "      <td>0.001152</td>\n",
       "      <td>-0.051422</td>\n",
       "      <td>-0.067751</td>\n",
       "      <td>-0.052096</td>\n",
       "      <td>0.010653</td>\n",
       "      <td>0.033482</td>\n",
       "      <td>0.104688</td>\n",
       "      <td>-0.043598</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005822</td>\n",
       "      <td>-0.068230</td>\n",
       "      <td>-0.032241</td>\n",
       "      <td>-0.010489</td>\n",
       "      <td>0.017251</td>\n",
       "      <td>0.043145</td>\n",
       "      <td>-0.109542</td>\n",
       "      <td>-0.017620</td>\n",
       "      <td>-0.018418</td>\n",
       "      <td>0.016671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2122</th>\n",
       "      <td>criminal justice reform advocate</td>\n",
       "      <td>-0.023893</td>\n",
       "      <td>-0.043973</td>\n",
       "      <td>-0.059823</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>0.045929</td>\n",
       "      <td>0.054473</td>\n",
       "      <td>0.042781</td>\n",
       "      <td>-0.049679</td>\n",
       "      <td>-0.020672</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027898</td>\n",
       "      <td>-0.009919</td>\n",
       "      <td>0.003572</td>\n",
       "      <td>-0.040371</td>\n",
       "      <td>-0.057846</td>\n",
       "      <td>0.079382</td>\n",
       "      <td>-0.007736</td>\n",
       "      <td>-0.009681</td>\n",
       "      <td>-0.032902</td>\n",
       "      <td>0.033930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>warner media</td>\n",
       "      <td>-0.037032</td>\n",
       "      <td>-0.009887</td>\n",
       "      <td>0.019396</td>\n",
       "      <td>0.019984</td>\n",
       "      <td>-0.058694</td>\n",
       "      <td>0.016678</td>\n",
       "      <td>0.052524</td>\n",
       "      <td>-0.019751</td>\n",
       "      <td>-0.101346</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.066676</td>\n",
       "      <td>-0.029724</td>\n",
       "      <td>0.058682</td>\n",
       "      <td>-0.007832</td>\n",
       "      <td>-0.039598</td>\n",
       "      <td>-0.014549</td>\n",
       "      <td>0.003396</td>\n",
       "      <td>0.038019</td>\n",
       "      <td>0.010487</td>\n",
       "      <td>0.009482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2771</th>\n",
       "      <td>stephen scherr</td>\n",
       "      <td>0.029316</td>\n",
       "      <td>-0.026960</td>\n",
       "      <td>-0.030501</td>\n",
       "      <td>-0.005422</td>\n",
       "      <td>-0.062781</td>\n",
       "      <td>0.028055</td>\n",
       "      <td>-0.049865</td>\n",
       "      <td>0.042824</td>\n",
       "      <td>0.059449</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026926</td>\n",
       "      <td>-0.050031</td>\n",
       "      <td>-0.028970</td>\n",
       "      <td>0.008073</td>\n",
       "      <td>-0.027069</td>\n",
       "      <td>0.095291</td>\n",
       "      <td>-0.002278</td>\n",
       "      <td>-0.032633</td>\n",
       "      <td>-0.012822</td>\n",
       "      <td>0.029524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>toptier london firm</td>\n",
       "      <td>0.040425</td>\n",
       "      <td>-0.019547</td>\n",
       "      <td>0.031787</td>\n",
       "      <td>-0.024443</td>\n",
       "      <td>0.004759</td>\n",
       "      <td>0.099513</td>\n",
       "      <td>0.084016</td>\n",
       "      <td>-0.035419</td>\n",
       "      <td>-0.035510</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018293</td>\n",
       "      <td>-0.004549</td>\n",
       "      <td>0.065829</td>\n",
       "      <td>-0.015718</td>\n",
       "      <td>-0.021190</td>\n",
       "      <td>-0.011539</td>\n",
       "      <td>-0.037094</td>\n",
       "      <td>0.003835</td>\n",
       "      <td>0.003796</td>\n",
       "      <td>0.001457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3420</th>\n",
       "      <td>results page</td>\n",
       "      <td>-0.020061</td>\n",
       "      <td>-0.005929</td>\n",
       "      <td>0.056879</td>\n",
       "      <td>0.101193</td>\n",
       "      <td>-0.046549</td>\n",
       "      <td>0.001252</td>\n",
       "      <td>0.002790</td>\n",
       "      <td>-0.004456</td>\n",
       "      <td>-0.054671</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046046</td>\n",
       "      <td>-0.043041</td>\n",
       "      <td>-0.038266</td>\n",
       "      <td>0.022771</td>\n",
       "      <td>0.044318</td>\n",
       "      <td>-0.084408</td>\n",
       "      <td>0.062654</td>\n",
       "      <td>-0.055787</td>\n",
       "      <td>0.072047</td>\n",
       "      <td>0.031095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1648</th>\n",
       "      <td>means tv</td>\n",
       "      <td>0.033786</td>\n",
       "      <td>0.032495</td>\n",
       "      <td>0.047863</td>\n",
       "      <td>0.038572</td>\n",
       "      <td>0.036241</td>\n",
       "      <td>-0.005764</td>\n",
       "      <td>-0.022428</td>\n",
       "      <td>-0.038650</td>\n",
       "      <td>-0.072621</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.036600</td>\n",
       "      <td>-0.019511</td>\n",
       "      <td>-0.027181</td>\n",
       "      <td>-0.027369</td>\n",
       "      <td>-0.026365</td>\n",
       "      <td>-0.044633</td>\n",
       "      <td>0.063320</td>\n",
       "      <td>-0.009151</td>\n",
       "      <td>-0.046448</td>\n",
       "      <td>-0.006127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4069</th>\n",
       "      <td>transitioning</td>\n",
       "      <td>-0.005565</td>\n",
       "      <td>0.012209</td>\n",
       "      <td>-0.006568</td>\n",
       "      <td>0.014643</td>\n",
       "      <td>-0.010678</td>\n",
       "      <td>-0.072128</td>\n",
       "      <td>0.018702</td>\n",
       "      <td>0.050759</td>\n",
       "      <td>-0.021658</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016809</td>\n",
       "      <td>0.000911</td>\n",
       "      <td>-0.018704</td>\n",
       "      <td>-0.007682</td>\n",
       "      <td>-0.078671</td>\n",
       "      <td>0.011638</td>\n",
       "      <td>-0.043829</td>\n",
       "      <td>-0.044602</td>\n",
       "      <td>0.008410</td>\n",
       "      <td>-0.038465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2297</th>\n",
       "      <td>manner</td>\n",
       "      <td>-0.034634</td>\n",
       "      <td>-0.017281</td>\n",
       "      <td>0.005216</td>\n",
       "      <td>-0.029388</td>\n",
       "      <td>-0.017066</td>\n",
       "      <td>-0.060915</td>\n",
       "      <td>0.002648</td>\n",
       "      <td>-0.041733</td>\n",
       "      <td>0.023275</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029764</td>\n",
       "      <td>-0.044668</td>\n",
       "      <td>0.007046</td>\n",
       "      <td>0.005024</td>\n",
       "      <td>-0.044133</td>\n",
       "      <td>-0.002735</td>\n",
       "      <td>0.031313</td>\n",
       "      <td>0.067484</td>\n",
       "      <td>-0.063666</td>\n",
       "      <td>0.036029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>new york state health commissioner dr. howard zucker</td>\n",
       "      <td>0.077196</td>\n",
       "      <td>-0.013401</td>\n",
       "      <td>-0.074933</td>\n",
       "      <td>-0.005931</td>\n",
       "      <td>0.052198</td>\n",
       "      <td>0.009870</td>\n",
       "      <td>-0.033601</td>\n",
       "      <td>-0.013025</td>\n",
       "      <td>0.014813</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029593</td>\n",
       "      <td>0.027719</td>\n",
       "      <td>0.091636</td>\n",
       "      <td>-0.004528</td>\n",
       "      <td>-0.054630</td>\n",
       "      <td>0.001851</td>\n",
       "      <td>-0.033052</td>\n",
       "      <td>0.020107</td>\n",
       "      <td>-0.075742</td>\n",
       "      <td>0.027206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2946</th>\n",
       "      <td>unused plastic bag</td>\n",
       "      <td>0.025587</td>\n",
       "      <td>0.087656</td>\n",
       "      <td>0.011059</td>\n",
       "      <td>0.072881</td>\n",
       "      <td>-0.056008</td>\n",
       "      <td>0.090132</td>\n",
       "      <td>0.024209</td>\n",
       "      <td>0.012330</td>\n",
       "      <td>-0.072024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043868</td>\n",
       "      <td>-0.003377</td>\n",
       "      <td>-0.046353</td>\n",
       "      <td>-0.024361</td>\n",
       "      <td>0.023305</td>\n",
       "      <td>-0.050749</td>\n",
       "      <td>-0.017718</td>\n",
       "      <td>0.069859</td>\n",
       "      <td>0.006933</td>\n",
       "      <td>-0.083325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1174</th>\n",
       "      <td>major winter sport</td>\n",
       "      <td>-0.024879</td>\n",
       "      <td>-0.054312</td>\n",
       "      <td>0.041965</td>\n",
       "      <td>0.052016</td>\n",
       "      <td>-0.059177</td>\n",
       "      <td>0.092939</td>\n",
       "      <td>-0.046839</td>\n",
       "      <td>-0.023206</td>\n",
       "      <td>0.045608</td>\n",
       "      <td>...</td>\n",
       "      <td>0.057513</td>\n",
       "      <td>-0.114603</td>\n",
       "      <td>0.035644</td>\n",
       "      <td>-0.021094</td>\n",
       "      <td>0.006538</td>\n",
       "      <td>0.047664</td>\n",
       "      <td>-0.050310</td>\n",
       "      <td>0.048835</td>\n",
       "      <td>0.027376</td>\n",
       "      <td>0.020105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3595</th>\n",
       "      <td>emergingmarket government</td>\n",
       "      <td>0.002180</td>\n",
       "      <td>0.003032</td>\n",
       "      <td>-0.040114</td>\n",
       "      <td>-0.035557</td>\n",
       "      <td>-0.067640</td>\n",
       "      <td>-0.089908</td>\n",
       "      <td>0.011296</td>\n",
       "      <td>-0.065511</td>\n",
       "      <td>0.054037</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003462</td>\n",
       "      <td>-0.070924</td>\n",
       "      <td>0.178217</td>\n",
       "      <td>-0.013591</td>\n",
       "      <td>-0.012282</td>\n",
       "      <td>0.057240</td>\n",
       "      <td>0.024152</td>\n",
       "      <td>-0.024548</td>\n",
       "      <td>-0.028082</td>\n",
       "      <td>0.090803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1823</th>\n",
       "      <td>quarrel</td>\n",
       "      <td>-0.017183</td>\n",
       "      <td>-0.000266</td>\n",
       "      <td>0.086995</td>\n",
       "      <td>-0.007909</td>\n",
       "      <td>-0.027447</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>-0.021957</td>\n",
       "      <td>0.060364</td>\n",
       "      <td>-0.014150</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.032568</td>\n",
       "      <td>-0.053995</td>\n",
       "      <td>-0.040652</td>\n",
       "      <td>-0.024613</td>\n",
       "      <td>-0.049143</td>\n",
       "      <td>0.058661</td>\n",
       "      <td>0.054391</td>\n",
       "      <td>0.090884</td>\n",
       "      <td>-0.054117</td>\n",
       "      <td>-0.025533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>bernard lowe jeffrey wright</td>\n",
       "      <td>0.001771</td>\n",
       "      <td>-0.005148</td>\n",
       "      <td>-0.050320</td>\n",
       "      <td>-0.032296</td>\n",
       "      <td>0.046990</td>\n",
       "      <td>-0.018460</td>\n",
       "      <td>0.020382</td>\n",
       "      <td>-0.023647</td>\n",
       "      <td>0.012877</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002915</td>\n",
       "      <td>0.029863</td>\n",
       "      <td>-0.041665</td>\n",
       "      <td>0.011335</td>\n",
       "      <td>0.026143</td>\n",
       "      <td>0.054891</td>\n",
       "      <td>-0.036745</td>\n",
       "      <td>0.052458</td>\n",
       "      <td>0.010554</td>\n",
       "      <td>0.094605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2472</th>\n",
       "      <td>meaningful regulation</td>\n",
       "      <td>0.066758</td>\n",
       "      <td>-0.017906</td>\n",
       "      <td>0.004453</td>\n",
       "      <td>-0.065399</td>\n",
       "      <td>-0.010459</td>\n",
       "      <td>-0.006418</td>\n",
       "      <td>0.000636</td>\n",
       "      <td>-0.019579</td>\n",
       "      <td>-0.020612</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028894</td>\n",
       "      <td>-0.077303</td>\n",
       "      <td>0.040616</td>\n",
       "      <td>-0.030384</td>\n",
       "      <td>-0.009766</td>\n",
       "      <td>-0.019139</td>\n",
       "      <td>-0.007859</td>\n",
       "      <td>-0.009715</td>\n",
       "      <td>-0.003746</td>\n",
       "      <td>-0.006517</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28 rows Ã 513 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      word     emb_0  \\\n",
       "0                                           rival fortnite -0.028948   \n",
       "2421                          philip morris internationals  0.071751   \n",
       "649                                              unplugged -0.044945   \n",
       "3070                                        annual meeting -0.083934   \n",
       "1298                   rigidly enforced gender expectation -0.020639   \n",
       "3719                                    postpothole repair  0.007223   \n",
       "1947                            republican senator jon kyl -0.074448   \n",
       "175                                magdalena zernickagoetz  0.004264   \n",
       "2596                                            nearly 2bn -0.035940   \n",
       "824                                          border angola -0.016436   \n",
       "3245                                          bus campaign -0.090365   \n",
       "1473                                     simpleton roombas  0.046562   \n",
       "3894                                          vast complex  0.027698   \n",
       "2122                      criminal justice reform advocate -0.023893   \n",
       "350                                           warner media -0.037032   \n",
       "2771                                        stephen scherr  0.029316   \n",
       "999                                    toptier london firm  0.040425   \n",
       "3420                                          results page -0.020061   \n",
       "1648                                              means tv  0.033786   \n",
       "4069                                         transitioning -0.005565   \n",
       "2297                                                manner -0.034634   \n",
       "525   new york state health commissioner dr. howard zucker  0.077196   \n",
       "2946                                    unused plastic bag  0.025587   \n",
       "1174                                    major winter sport -0.024879   \n",
       "3595                             emergingmarket government  0.002180   \n",
       "1823                                               quarrel -0.017183   \n",
       "51                             bernard lowe jeffrey wright  0.001771   \n",
       "2472                                 meaningful regulation  0.066758   \n",
       "\n",
       "         emb_1     emb_2     emb_3     emb_4     emb_5     emb_6     emb_7  \\\n",
       "0     0.064054  0.014190  0.073210 -0.088359  0.110766  0.077670  0.035829   \n",
       "2421  0.058493 -0.002705  0.040606 -0.022526  0.081023 -0.014479  0.043452   \n",
       "649   0.019505  0.042838 -0.024796 -0.085768 -0.033376  0.019646  0.065180   \n",
       "3070 -0.006209 -0.011543 -0.071184  0.041844  0.046135 -0.012820 -0.112799   \n",
       "1298  0.051757 -0.024310 -0.052477  0.064120 -0.079127 -0.069198  0.018345   \n",
       "3719 -0.036479 -0.012374  0.029721 -0.004580 -0.002598 -0.000942  0.003334   \n",
       "1947  0.017038 -0.037902 -0.011970  0.002294  0.048126 -0.020591  0.006250   \n",
       "175   0.018595  0.012869  0.032346  0.016008  0.017975  0.048702 -0.011801   \n",
       "2596  0.005396 -0.032637  0.071618 -0.031461  0.046243 -0.011780  0.033512   \n",
       "824   0.029175 -0.115872 -0.052781  0.047338 -0.025110 -0.045445  0.012612   \n",
       "3245 -0.011007 -0.026151 -0.059735 -0.013370  0.014698 -0.063526 -0.021808   \n",
       "1473 -0.003330  0.049606  0.009292  0.033348 -0.046104  0.074190  0.035382   \n",
       "3894  0.001152 -0.051422 -0.067751 -0.052096  0.010653  0.033482  0.104688   \n",
       "2122 -0.043973 -0.059823  0.000119  0.045929  0.054473  0.042781 -0.049679   \n",
       "350  -0.009887  0.019396  0.019984 -0.058694  0.016678  0.052524 -0.019751   \n",
       "2771 -0.026960 -0.030501 -0.005422 -0.062781  0.028055 -0.049865  0.042824   \n",
       "999  -0.019547  0.031787 -0.024443  0.004759  0.099513  0.084016 -0.035419   \n",
       "3420 -0.005929  0.056879  0.101193 -0.046549  0.001252  0.002790 -0.004456   \n",
       "1648  0.032495  0.047863  0.038572  0.036241 -0.005764 -0.022428 -0.038650   \n",
       "4069  0.012209 -0.006568  0.014643 -0.010678 -0.072128  0.018702  0.050759   \n",
       "2297 -0.017281  0.005216 -0.029388 -0.017066 -0.060915  0.002648 -0.041733   \n",
       "525  -0.013401 -0.074933 -0.005931  0.052198  0.009870 -0.033601 -0.013025   \n",
       "2946  0.087656  0.011059  0.072881 -0.056008  0.090132  0.024209  0.012330   \n",
       "1174 -0.054312  0.041965  0.052016 -0.059177  0.092939 -0.046839 -0.023206   \n",
       "3595  0.003032 -0.040114 -0.035557 -0.067640 -0.089908  0.011296 -0.065511   \n",
       "1823 -0.000266  0.086995 -0.007909 -0.027447  0.000714 -0.021957  0.060364   \n",
       "51   -0.005148 -0.050320 -0.032296  0.046990 -0.018460  0.020382 -0.023647   \n",
       "2472 -0.017906  0.004453 -0.065399 -0.010459 -0.006418  0.000636 -0.019579   \n",
       "\n",
       "         emb_8  ...   emb_502   emb_503   emb_504   emb_505   emb_506  \\\n",
       "0    -0.032533  ... -0.042242 -0.030448 -0.030571 -0.032998  0.034555   \n",
       "2421 -0.051692  ...  0.035390 -0.051603 -0.014338 -0.007827  0.075689   \n",
       "649  -0.061526  ...  0.072080  0.064702 -0.025158 -0.011246 -0.058174   \n",
       "3070  0.030378  ... -0.026774  0.015173  0.041242  0.017139  0.021064   \n",
       "1298 -0.065469  ...  0.068233  0.042767 -0.023927 -0.012723 -0.028446   \n",
       "3719 -0.040680  ... -0.033686 -0.029744  0.007175 -0.008106 -0.031989   \n",
       "1947 -0.027261  ... -0.036317 -0.027186  0.125992  0.015419 -0.039449   \n",
       "175  -0.042248  ... -0.007407 -0.020057 -0.000438  0.023585 -0.046515   \n",
       "2596  0.061371  ... -0.065193 -0.060827 -0.003603  0.006782 -0.003571   \n",
       "824  -0.048793  ... -0.010449 -0.112085  0.114980 -0.005818 -0.031272   \n",
       "3245  0.033240  ... -0.049083 -0.004245  0.046844 -0.016459 -0.017473   \n",
       "1473  0.002309  ...  0.012698  0.031249 -0.044579 -0.027117 -0.005787   \n",
       "3894 -0.043598  ...  0.005822 -0.068230 -0.032241 -0.010489  0.017251   \n",
       "2122 -0.020672  ... -0.027898 -0.009919  0.003572 -0.040371 -0.057846   \n",
       "350  -0.101346  ... -0.066676 -0.029724  0.058682 -0.007832 -0.039598   \n",
       "2771  0.059449  ... -0.026926 -0.050031 -0.028970  0.008073 -0.027069   \n",
       "999  -0.035510  ...  0.018293 -0.004549  0.065829 -0.015718 -0.021190   \n",
       "3420 -0.054671  ... -0.046046 -0.043041 -0.038266  0.022771  0.044318   \n",
       "1648 -0.072621  ... -0.036600 -0.019511 -0.027181 -0.027369 -0.026365   \n",
       "4069 -0.021658  ...  0.016809  0.000911 -0.018704 -0.007682 -0.078671   \n",
       "2297  0.023275  ... -0.029764 -0.044668  0.007046  0.005024 -0.044133   \n",
       "525   0.014813  ...  0.029593  0.027719  0.091636 -0.004528 -0.054630   \n",
       "2946 -0.072024  ...  0.043868 -0.003377 -0.046353 -0.024361  0.023305   \n",
       "1174  0.045608  ...  0.057513 -0.114603  0.035644 -0.021094  0.006538   \n",
       "3595  0.054037  ... -0.003462 -0.070924  0.178217 -0.013591 -0.012282   \n",
       "1823 -0.014150  ... -0.032568 -0.053995 -0.040652 -0.024613 -0.049143   \n",
       "51    0.012877  ...  0.002915  0.029863 -0.041665  0.011335  0.026143   \n",
       "2472 -0.020612  ...  0.028894 -0.077303  0.040616 -0.030384 -0.009766   \n",
       "\n",
       "       emb_507   emb_508   emb_509   emb_510   emb_511  \n",
       "0     0.113697  0.018538  0.038067 -0.000274  0.024339  \n",
       "2421  0.006039 -0.022070 -0.014119  0.066530  0.036217  \n",
       "649  -0.105868  0.006102 -0.044000 -0.010283 -0.025208  \n",
       "3070  0.052726  0.011243  0.062688  0.013496 -0.055573  \n",
       "1298  0.042471 -0.007701 -0.015071  0.005724 -0.003037  \n",
       "3719  0.044643 -0.019443 -0.005706 -0.006232  0.067022  \n",
       "1947  0.055503 -0.024551  0.076030 -0.022705 -0.019698  \n",
       "175   0.003248  0.001250  0.018682 -0.015019  0.022444  \n",
       "2596  0.047496 -0.034156  0.002539  0.012971  0.039395  \n",
       "824   0.061169  0.032391  0.069337 -0.006547 -0.051745  \n",
       "3245 -0.011006 -0.011537  0.060725 -0.000908 -0.027614  \n",
       "1473  0.041612 -0.015210  0.046340  0.005281 -0.093688  \n",
       "3894  0.043145 -0.109542 -0.017620 -0.018418  0.016671  \n",
       "2122  0.079382 -0.007736 -0.009681 -0.032902  0.033930  \n",
       "350  -0.014549  0.003396  0.038019  0.010487  0.009482  \n",
       "2771  0.095291 -0.002278 -0.032633 -0.012822  0.029524  \n",
       "999  -0.011539 -0.037094  0.003835  0.003796  0.001457  \n",
       "3420 -0.084408  0.062654 -0.055787  0.072047  0.031095  \n",
       "1648 -0.044633  0.063320 -0.009151 -0.046448 -0.006127  \n",
       "4069  0.011638 -0.043829 -0.044602  0.008410 -0.038465  \n",
       "2297 -0.002735  0.031313  0.067484 -0.063666  0.036029  \n",
       "525   0.001851 -0.033052  0.020107 -0.075742  0.027206  \n",
       "2946 -0.050749 -0.017718  0.069859  0.006933 -0.083325  \n",
       "1174  0.047664 -0.050310  0.048835  0.027376  0.020105  \n",
       "3595  0.057240  0.024152 -0.024548 -0.028082  0.090803  \n",
       "1823  0.058661  0.054391  0.090884 -0.054117 -0.025533  \n",
       "51    0.054891 -0.036745  0.052458  0.010554  0.094605  \n",
       "2472 -0.019139 -0.007859 -0.009715 -0.003746 -0.006517  \n",
       "\n",
       "[28 rows x 513 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_w2v.iloc[::15000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next:\n",
    "- Unet\n",
    "- HDBSCAN\n",
    "- defining cluster center names (key words)\n",
    "- replacing texts with list of key-words\n",
    "- running LDA\n",
    "\n",
    "\n",
    "https://towardsdatascience.com/topic-modeling-with-bert-779f7db187e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "GLG - 3_step - Assigning Text Groups.ipynb",
   "toc_visible": true,
   "version": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "305.455px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
