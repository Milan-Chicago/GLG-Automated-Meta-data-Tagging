{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting data for model training and testing\n",
    "- Since GLG is interested in short text topic modeling (abstracts from client request), only part of news text is needed\n",
    "- Test data is taken from well defined sections to see if all news from those sect6ions go at least to first level cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data and python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tatiana/opt/anaconda3/lib/python3.7/site-packages/spacy/util.py:275: UserWarning: [W031] Model 'en_core_web_sm' (2.2.0) requires spaCy v2.2 and is incompatible with the current spaCy version (2.3.5). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "# data processing libraries\n",
    "import pandas as pd\n",
    "\n",
    "# display wider columns in pandas data frames where necessary\n",
    "pd.set_option('max_colwidth',150)\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# supporting libraries\n",
    "import re\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file location of the data\n",
    "input_folder = './data/'\n",
    "output_folder = './transition_files/'\n",
    "\n",
    "file_name = 'all-the-news-2-1.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tatiana/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3072: DtypeWarning: Columns (1,3,5) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2688879, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <td>2016-12-09 18:31:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>author</th>\n",
       "      <td>Lee Drutman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <td>We should take concerns about the health of liberal democracy seriously</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article</th>\n",
       "      <td>This post is part of Polyarchy, an independent blog produced by the political reform program at New America, a Washington think tank devoted to de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>url</th>\n",
       "      <td>https://www.vox.com/polyarchy/2016/12/9/13898340/democracy-warning-signs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>section</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>publication</th>\n",
       "      <td>Vox</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                  0\n",
       "Unnamed: 0                                                                                                                                                        0\n",
       "Unnamed: 0.1                                                                                                                                                      0\n",
       "date                                                                                                                                            2016-12-09 18:31:00\n",
       "year                                                                                                                                                           2016\n",
       "month                                                                                                                                                            12\n",
       "day                                                                                                                                                               9\n",
       "author                                                                                                                                                  Lee Drutman\n",
       "title                                                                                       We should take concerns about the health of liberal democracy seriously\n",
       "article       This post is part of Polyarchy, an independent blog produced by the political reform program at New America, a Washington think tank devoted to de...\n",
       "url                                                                                        https://www.vox.com/polyarchy/2016/12/9/13898340/democracy-warning-signs\n",
       "section                                                                                                                                                         NaN\n",
       "publication                                                                                                                                                     Vox"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "df_data = pd.read_csv(input_folder + file_name, #file location\n",
    "                      encoding = \"ISO-8859-1\", #deal with texts in different formats\n",
    "                     )\n",
    "\n",
    "# display first row of the data frame\n",
    "print(df_data.shape)\n",
    "df_data.head(1).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean and selecting first few paragraphs (10 sentences) for selected publications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1660535, 12)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select ONLY data with specified section and publication and non-duplicated texts of article\n",
    "df_data['publication'] = df_data['publication'].fillna(\"\")\n",
    "df_data = df_data[df_data['publication'].apply(len)>0]\n",
    "\n",
    "df_data['section'] = df_data['section'].fillna(\"\")\n",
    "df_data = df_data[df_data['section'].apply(len)>0]\n",
    "\n",
    "df_data['article'] = df_data['article'].fillna(\"\")\n",
    "df_data = df_data[df_data['article'].apply(len)>0]\n",
    "df_data = df_data.drop_duplicates('article')\n",
    "\n",
    "df_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique values:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>section</th>\n",
       "      <th>article</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>publication</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CNBC</th>\n",
       "      <td>634</td>\n",
       "      <td>191185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CNN</th>\n",
       "      <td>63</td>\n",
       "      <td>124659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Economist</th>\n",
       "      <td>46</td>\n",
       "      <td>23050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fox News</th>\n",
       "      <td>670</td>\n",
       "      <td>20130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gizmodo</th>\n",
       "      <td>78</td>\n",
       "      <td>18214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New Yorker</th>\n",
       "      <td>1</td>\n",
       "      <td>4644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>People</th>\n",
       "      <td>35</td>\n",
       "      <td>133766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reuters</th>\n",
       "      <td>224</td>\n",
       "      <td>734147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The New York Times</th>\n",
       "      <td>3774</td>\n",
       "      <td>240107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Verge</th>\n",
       "      <td>148</td>\n",
       "      <td>50201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vice</th>\n",
       "      <td>1324</td>\n",
       "      <td>100347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Washington Post</th>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wired</th>\n",
       "      <td>28</td>\n",
       "      <td>20057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    section  article\n",
       "publication                         \n",
       "CNBC                    634   191185\n",
       "CNN                      63   124659\n",
       "Economist                46    23050\n",
       "Fox News                670    20130\n",
       "Gizmodo                  78    18214\n",
       "New Yorker                1     4644\n",
       "People                   35   133766\n",
       "Reuters                 224   734147\n",
       "The New York Times     3774   240107\n",
       "The Verge               148    50201\n",
       "Vice                   1324   100347\n",
       "Washington Post           5       28\n",
       "Wired                    28    20057"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Publications in the data\n",
    "print('Number of unique values:')\n",
    "df = df_data.groupby('publication')[['section', 'article']].nunique()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'article',\n",
       " 'artificial-intelligence',\n",
       " 'backchannel',\n",
       " 'business',\n",
       " 'culture',\n",
       " 'deals',\n",
       " 'design',\n",
       " 'environment',\n",
       " 'gadget-lab-podcast',\n",
       " 'gadgetlab',\n",
       " 'gear',\n",
       " 'ideas',\n",
       " 'magazine',\n",
       " 'music',\n",
       " 'national-affairs',\n",
       " 'opinion',\n",
       " 'outdoor',\n",
       " 'phones',\n",
       " 'photo',\n",
       " 'physics-math',\n",
       " 'privacy',\n",
       " 'reviews',\n",
       " 'science',\n",
       " 'security',\n",
       " 'social-media',\n",
       " 'transportation',\n",
       " 'trends',\n",
       " 'uncategorized'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check each pablication\n",
    "set(df_data[df_data['publication'] == \"Wired\"]['section'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "section       250\n",
      "article    319746\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>section</th>\n",
       "      <th>article</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>publication</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CNN</th>\n",
       "      <td>63</td>\n",
       "      <td>124659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Economist</th>\n",
       "      <td>46</td>\n",
       "      <td>23050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gizmodo</th>\n",
       "      <td>78</td>\n",
       "      <td>18214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>People</th>\n",
       "      <td>35</td>\n",
       "      <td>133766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wired</th>\n",
       "      <td>28</td>\n",
       "      <td>20057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             section  article\n",
       "publication                  \n",
       "CNN               63   124659\n",
       "Economist         46    23050\n",
       "Gizmodo           78    18214\n",
       "People            35   133766\n",
       "Wired             28    20057"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select only publications with more than 10 sections and less than 100\n",
    "df=df[(df['section'] > 10) & (df['section'] < 100)]\n",
    "print(df.sum())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CNN', 'Economist', 'Gizmodo', 'People', 'Wired']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_publications = list(df.index)\n",
    "selected_publications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(319746, 12)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data = df_data[df_data['publication'].isin(selected_publications)]\n",
    "df_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean text\n",
    "df_data['article'] = df_data['article'].str.replace(r\"[^A-Za-z0-9//-/.,!?:; ]\",'', regex=True)\n",
    "\n",
    "#select texts that have at least 500 but no more than 10000 symbols\n",
    "df_data['text_length'] = df_data['article'].fillna(\"\").apply(len)\n",
    "df_data = df_data[df_data['text_length'] >= 500]\n",
    "df_data = df_data[df_data['text_length'] < 10000]\n",
    "\n",
    "# cut text to have no more than 1500 symbols\n",
    "df_data['article'] = df_data['article'].str[:1500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = df_data.reset_index(drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 50001 0\n",
      "1 50001 50000\n",
      "2 50001 100000\n",
      "3 50001 150000\n",
      "4 50001 200000\n",
      "5 50001 250000\n",
      "6 6365 300000\n"
     ]
    }
   ],
   "source": [
    "# split on the data sub-samples of 50,000 records each \n",
    "# and save for next steps\n",
    "k = 0\n",
    "batch_size = 50000\n",
    "\n",
    "for k in range(7):\n",
    "    df_part = df_data.loc[k * batch_size: (k+1) * batch_size,:]\n",
    "    print(k, len(df_part), df_part.index[0])\n",
    "    with open(output_folder + 'data_part_'+str(k)+'.pickle', 'wb') as f:\n",
    "        # Pickle the 'data' dictionary using the highest protocol available.\n",
    "        pickle.dump(df_part, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting first few paragraphs (10 sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "CPU times: user 18min 9s, sys: 3.79 s, total: 18min 13s\n",
      "Wall time: 18min 14s\n",
      "==================================================\n",
      "6\n",
      "CPU times: user 2min 30s, sys: 1.14 s, total: 2min 32s\n",
      "Wall time: 2min 32s\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "for k in range(5,7,1):\n",
    "    file_name = 'data_part_'+str(k)+'.pickle'\n",
    "\n",
    "    # load data\n",
    "    with open(output_folder + file_name, 'rb') as f:\n",
    "        # The protocol version used is detected automatically, so we do not\n",
    "        # have to specify it.\n",
    "        df_data = pickle.load(f)\n",
    "\n",
    "    #get spaCy doc\n",
    "    print(k)\n",
    "    %time df_data['spacy_doc'] = df_data['article'].apply(lambda x: nlp(x))\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    #delete text of article\n",
    "    del df_data['article']\n",
    "    \n",
    "    #select first 10 sentenses\n",
    "    df_data['first_10_sents'] = df_data['spacy_doc'].apply(lambda doc: list(doc.sents)[:10])\n",
    "    df_data['first_10_sents'] = df_data['first_10_sents'].apply(lambda l: \" \".join([s.text for s in l]))\n",
    "\n",
    "    #save batch as pickle\n",
    "    with open(output_folder + 'spacy_doc_' +str(k)+ '.pickle', 'wb') as f:\n",
    "        # Pickle the 'data' dictionary using the highest protocol available.\n",
    "        pickle.dump(df_data, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Test and Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spacy_doc_0.pickle\n",
      "spacy_doc_1.pickle\n",
      "spacy_doc_2.pickle\n",
      "spacy_doc_3.pickle\n",
      "spacy_doc_4.pickle\n",
      "spacy_doc_5.pickle\n",
      "spacy_doc_6.pickle\n"
     ]
    }
   ],
   "source": [
    "list_dfs = []\n",
    "\n",
    "for k in range(7):\n",
    "    file_name = 'spacy_doc_' +str(k)+ '.pickle'\n",
    "    print(file_name)\n",
    "\n",
    "    # load data\n",
    "    with open(output_folder + file_name, 'rb') as f:\n",
    "        # The protocol version used is detected automatically, so we do not\n",
    "        # have to specify it.\n",
    "        df_data = pickle.load(f)\n",
    "\n",
    "    #delete 'spacy_doc' of article \n",
    "    #(it is used for LDA model but we need only text of first 10 sentenses for other models)\n",
    "    del df_data['spacy_doc']\n",
    "    \n",
    "    list_dfs.append(df_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(306371, 14)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['index', 'Unnamed: 0', 'Unnamed: 0.1', 'date', 'year', 'month', 'day',\n",
       "       'author', 'title', 'url', 'section', 'publication', 'text_length',\n",
       "       'first_10_sents'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data = pd.concat(list_dfs)\n",
    "print(df_data.shape)\n",
    "df_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120324, 14)\n"
     ]
    }
   ],
   "source": [
    "#Save Test data (CNN articles)\n",
    "df_test = df_data[df_data['publication'] == \"CNN\"]\n",
    "print(df_test.shape)\n",
    "df_test[[\"date\", 'author', \n",
    "         'title', 'url', \n",
    "         'section', 'publication',\n",
    "         'first_10_sents']].to_csv(output_folder + \"test.tsv\", index=False, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(186047, 14)\n"
     ]
    }
   ],
   "source": [
    "#Save Train data (all but CNN articles)\n",
    "df_train = df_data[df_data['publication'] != \"CNN\"]\n",
    "print(df_train.shape)\n",
    "df_train[[\"date\", 'author', \n",
    "         'title', 'url', \n",
    "         'section', 'publication',\n",
    "         'first_10_sents']].to_csv(output_folder + \"train.tsv\", index=False, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data articles by publications:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "publication\n",
       "Economist     21613\n",
       "Gizmodo       17458\n",
       "People       130726\n",
       "Wired         16250\n",
       "Name: first_10_sents, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#publicaztions in Train dataset\n",
    "print(\"Train data articles by publications:\")\n",
    "df_train.groupby('publication')['first_10_sents'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "305.455px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
