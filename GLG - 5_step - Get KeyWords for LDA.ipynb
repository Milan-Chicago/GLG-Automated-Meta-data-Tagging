{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Idea:\n",
    "Our solution: LDA + BERT based embeddings of noun phrases and verbs :\n",
    "- Each noun phrase and verb in the texts is  transformed to embedding vector using Universal Sentence Encoder (transformer based on BERT)\n",
    "- Embedding vectors from (a) are clustered (HDBSCAN + UNET)\n",
    "- Words/phrases with embedding vectors closest to the centers of resulting clusters form key word/phrase\n",
    "- Each text in the training sample is converted to collection of key-phrases by replacing its noun phrases and verbs with keyword/phrases and deleting other words\n",
    "- LDA is performed on the transformed texts\n",
    "\n",
    "\n",
    "**Reference:**<br>\n",
    "- Daniel Cer, Yinfei Yang, Sheng-yi Kong, Nan Hua, Nicole Limtiaco, Rhomni St. John, Noah Constant, Mario Guajardo-CÃ©spedes, Steve Yuan, Chris Tar, Yun-Hsuan Sung, Brian Strope, Ray Kurzweil. **Universal Sentence Encoder.** *arXiv:1803.11175, 2018.*\n",
    "- McInnes, L, Healy, J, **UMAP: Uniform Manifold Approximation and Projection for Dimension Reduction**, *ArXiv e-prints 1802.03426, 2018*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "clNUUp3MUO2t"
   },
   "source": [
    "# Load data and python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1622131163361,
     "user": {
      "displayName": "Tatiana Chebonenko",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgwGu7u_TizJ74HmaMD0AtIfiksMdhRYrfZtevXzQ=s64",
      "userId": "10264586744881678851"
     },
     "user_tz": 240
    },
    "id": "7dYQIbH6UO2u"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.2.0\n",
      "module https://tfhub.dev/google/universal-sentence-encoder-large/5 loaded\n"
     ]
    }
   ],
   "source": [
    "# data processing libraries\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "# display wider columns in pandas data frames where necessary\n",
    "pd.set_option('max_colwidth',150)\n",
    "\n",
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "#Load the Universal Sentence Encoder's TF Hub module\n",
    "module_url = \"https://tfhub.dev/google/universal-sentence-encoder-large/5\"\n",
    "model = hub.load(module_url)\n",
    "print (\"module %s loaded\" % module_url)\n",
    "\n",
    "import umap\n",
    "import hdbscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train.shape: (33982, 16)\n",
      "df_train.shape: Index(['date', 'author', 'title', 'url', 'section', 'publication',\n",
      "       'first_10_sents', 'list_of_first_10_sents', 'list_of_verb_lemmas',\n",
      "       'noun_phrases', 'list_of_nouns', 'list_of_lemmas', 'ID',\n",
      "       'group_level_1', 'group_level_2', 'group_level_3'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"./data/train_grouped.tsv\", sep=\"\\t\")\n",
    "print(\"df_train.shape:\", df_train.shape)\n",
    "print(\"df_train.shape:\",df_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Bxk10XYUqNp"
   },
   "source": [
    "# Getting text clusters through sentence embedding comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1622131190534,
     "user": {
      "displayName": "Tatiana Chebonenko",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgwGu7u_TizJ74HmaMD0AtIfiksMdhRYrfZtevXzQ=s64",
      "userId": "10264586744881678851"
     },
     "user_tz": 240
    },
    "id": "MsgF9abaX2Bn"
   },
   "outputs": [],
   "source": [
    "def get_embeddings(input):\n",
    "    return model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_embeddings(df_data, column = \"word\", N_batches=1):\n",
    "    #split data into N batches\n",
    "    N = N_batches\n",
    "\n",
    "    part = int(len(df_data)/N)\n",
    "    print(N, \"batches with\", part + 1, column + \"s each\")\n",
    "\n",
    "    #get embeddings for each N words\n",
    "    index = 0\n",
    "    batch_num = 0\n",
    "    list_dfs = []\n",
    "\n",
    "    while index < len(df_data): \n",
    "        df_tmp = df_data.iloc[index : index + part].copy()\n",
    "        df_tmp = df_tmp.reset_index(drop=True)\n",
    "        print (\"Batch number:\", batch_num + 1, \"out of \", N)\n",
    "\n",
    "        df_batch_embeddings = pd.DataFrame(get_embeddings(list(df_tmp[column])).numpy())\n",
    "\n",
    "        num_embeddings = df_batch_embeddings.shape[1]\n",
    "        columns = [\"emb_\" + str(i) for i in range(512)]\n",
    "        df_tmp[columns] = df_batch_embeddings\n",
    "\n",
    "        list_dfs.append(df_tmp)\n",
    "        batch_num = batch_num + 1\n",
    "        index = index + part\n",
    "\n",
    "    #concatinate batches into single dataset\n",
    "    df_emb = pd.concat(list_dfs)\n",
    "\n",
    "    return df_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [rise, big emerging economy, china, india, steady march, globalisation, surge, number, people, business, tourism, result, demand, visa, unpreceden...\n",
       "1    [pfizer, commitment, corporate social responsibility csr, drugs giant talk, responsibility, society, world, access, product, work, ngos, global he...\n",
       "2    [week, federal reserve, interest rate, time, year, world, central bank, rate, recent year, long spell, course, chart, outcome, americas rate rise,...\n",
       "3    [cruise line, wave, year, nearly, holiday, sea, result, december 18th carnival, worlds largest operator, global market, fullyear earning, demand, ...\n",
       "4    [investors, calendar year, buoyant mood, unexpected event, consensus, respect, view, investor, market price, column, potential surprise, definitio...\n",
       "Name: noun_phrases, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['noun_phrases'] = df_train['noun_phrases'].str[2:-2]\n",
    "df_train['noun_phrases'] = df_train['noun_phrases'].str.lower().str.split(\"', '\")\n",
    "df_train['noun_phrases'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['rise', 'big emerging economy', 'china', 'india', 'steady march'], 1417049)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_NPs = list(df_train['noun_phrases'])\n",
    "all_NPs = [np for l in all_NPs for np in l if len(np)>0]\n",
    "all_NPs[:5], len(all_NPs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[emerging, led, wanting, travel, granted, Upgrade, travel, apply, submit, streamline, scrap]'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['list_of_verb_lemmas'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                               [merging, led, wanting, travel, granted, upgrade, travel, apply, submit, streamline, scra]\n",
       "1    [rided, embracing, insists, gain, strengthen, improve, deterred, seeking, intends, shift, domiciled, rejoiced, saved, paid, outraged, promised, im...\n",
       "2    [aised, ended, celebrate, tried, lift, forced, reverse, cut, help, understand, upgrade, strike, wish, save, spend, try, escape, slashing, encourag...\n",
       "3      [race, booked, improve, announced, control, demand, peaking, piling, based, got, moving, upgrade, increase, announced, establish, aimed, based, ad]\n",
       "4    [tart, caught, proved, reflected, like, suggest, judged, betting, expect, upgrade, weakens, having, pushed, tighten, buy, priced, doubt, tighten, ...\n",
       "Name: list_of_verb_lemmas, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['list_of_verb_lemmas'] = df_train['list_of_verb_lemmas'].str[2:-2]\n",
    "df_train['list_of_verb_lemmas'] = df_train['list_of_verb_lemmas'].str.lower().str.split(\", \")\n",
    "df_train['list_of_verb_lemmas'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['merging', 'led', 'wanting', 'travel', 'granted'], 675330)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_Vs = list(df_train['list_of_verb_lemmas'])\n",
    "all_Vs = [v for l in all_Vs for v in l if len(v)>0]\n",
    "all_Vs[:5], len(all_Vs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "419327"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words =  list(set(all_NPs + all_Vs))\n",
    "len(set(all_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "0_QElB-4UM2z",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>illegal trade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>universal free health care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>deadly consequence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>users activity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>soonthe company</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         word\n",
       "0               illegal trade\n",
       "1  universal free health care\n",
       "2          deadly consequence\n",
       "3              users activity\n",
       "4             soonthe company"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_words = pd.DataFrame({'word': all_words})\n",
    "df_words.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 batches with 4194 words each\n",
      "Batch number: 1 out of  100\n",
      "Batch number: 2 out of  100\n",
      "Batch number: 3 out of  100\n",
      "Batch number: 4 out of  100\n",
      "Batch number: 5 out of  100\n",
      "Batch number: 6 out of  100\n",
      "Batch number: 7 out of  100\n",
      "Batch number: 8 out of  100\n",
      "Batch number: 9 out of  100\n",
      "Batch number: 10 out of  100\n",
      "Batch number: 11 out of  100\n",
      "Batch number: 12 out of  100\n",
      "Batch number: 13 out of  100\n",
      "Batch number: 14 out of  100\n",
      "Batch number: 15 out of  100\n",
      "Batch number: 16 out of  100\n",
      "Batch number: 17 out of  100\n",
      "Batch number: 18 out of  100\n",
      "Batch number: 19 out of  100\n",
      "Batch number: 20 out of  100\n",
      "Batch number: 21 out of  100\n",
      "Batch number: 22 out of  100\n",
      "Batch number: 23 out of  100\n",
      "Batch number: 24 out of  100\n",
      "Batch number: 25 out of  100\n",
      "Batch number: 26 out of  100\n",
      "Batch number: 27 out of  100\n",
      "Batch number: 28 out of  100\n",
      "Batch number: 29 out of  100\n",
      "Batch number: 30 out of  100\n",
      "Batch number: 31 out of  100\n",
      "Batch number: 32 out of  100\n",
      "Batch number: 33 out of  100\n",
      "Batch number: 34 out of  100\n",
      "Batch number: 35 out of  100\n",
      "Batch number: 36 out of  100\n",
      "Batch number: 37 out of  100\n",
      "Batch number: 38 out of  100\n",
      "Batch number: 39 out of  100\n",
      "Batch number: 40 out of  100\n",
      "Batch number: 41 out of  100\n",
      "Batch number: 42 out of  100\n",
      "Batch number: 43 out of  100\n",
      "Batch number: 44 out of  100\n",
      "Batch number: 45 out of  100\n",
      "Batch number: 46 out of  100\n",
      "Batch number: 47 out of  100\n",
      "Batch number: 48 out of  100\n",
      "Batch number: 49 out of  100\n",
      "Batch number: 50 out of  100\n",
      "Batch number: 51 out of  100\n",
      "Batch number: 52 out of  100\n",
      "Batch number: 53 out of  100\n",
      "Batch number: 54 out of  100\n",
      "Batch number: 55 out of  100\n",
      "Batch number: 56 out of  100\n",
      "Batch number: 57 out of  100\n",
      "Batch number: 58 out of  100\n",
      "Batch number: 59 out of  100\n",
      "Batch number: 60 out of  100\n",
      "Batch number: 61 out of  100\n",
      "Batch number: 62 out of  100\n",
      "Batch number: 63 out of  100\n",
      "Batch number: 64 out of  100\n",
      "Batch number: 65 out of  100\n",
      "Batch number: 66 out of  100\n",
      "Batch number: 67 out of  100\n",
      "Batch number: 68 out of  100\n",
      "Batch number: 69 out of  100\n",
      "Batch number: 70 out of  100\n",
      "Batch number: 71 out of  100\n",
      "Batch number: 72 out of  100\n",
      "Batch number: 73 out of  100\n",
      "Batch number: 74 out of  100\n",
      "Batch number: 75 out of  100\n",
      "Batch number: 76 out of  100\n",
      "Batch number: 77 out of  100\n",
      "Batch number: 78 out of  100\n",
      "Batch number: 79 out of  100\n",
      "Batch number: 80 out of  100\n",
      "Batch number: 81 out of  100\n",
      "Batch number: 82 out of  100\n",
      "Batch number: 83 out of  100\n",
      "Batch number: 84 out of  100\n",
      "Batch number: 85 out of  100\n",
      "Batch number: 86 out of  100\n",
      "Batch number: 87 out of  100\n",
      "Batch number: 88 out of  100\n",
      "Batch number: 89 out of  100\n",
      "Batch number: 90 out of  100\n",
      "Batch number: 91 out of  100\n",
      "Batch number: 92 out of  100\n",
      "Batch number: 93 out of  100\n",
      "Batch number: 94 out of  100\n",
      "Batch number: 95 out of  100\n",
      "Batch number: 96 out of  100\n",
      "Batch number: 97 out of  100\n",
      "Batch number: 98 out of  100\n",
      "Batch number: 99 out of  100\n",
      "Batch number: 100 out of  100\n",
      "Batch number: 101 out of  100\n",
      "CPU times: user 51min 3s, sys: 2min 15s, total: 53min 19s\n",
      "Wall time: 5min 8s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>emb_0</th>\n",
       "      <th>emb_1</th>\n",
       "      <th>emb_2</th>\n",
       "      <th>emb_3</th>\n",
       "      <th>emb_4</th>\n",
       "      <th>emb_5</th>\n",
       "      <th>emb_6</th>\n",
       "      <th>emb_7</th>\n",
       "      <th>emb_8</th>\n",
       "      <th>...</th>\n",
       "      <th>emb_502</th>\n",
       "      <th>emb_503</th>\n",
       "      <th>emb_504</th>\n",
       "      <th>emb_505</th>\n",
       "      <th>emb_506</th>\n",
       "      <th>emb_507</th>\n",
       "      <th>emb_508</th>\n",
       "      <th>emb_509</th>\n",
       "      <th>emb_510</th>\n",
       "      <th>emb_511</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>illegal trade</td>\n",
       "      <td>0.088174</td>\n",
       "      <td>-0.024202</td>\n",
       "      <td>0.032902</td>\n",
       "      <td>0.034414</td>\n",
       "      <td>-0.043001</td>\n",
       "      <td>0.047338</td>\n",
       "      <td>-0.000035</td>\n",
       "      <td>0.001882</td>\n",
       "      <td>-0.032775</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025584</td>\n",
       "      <td>0.000864</td>\n",
       "      <td>0.052648</td>\n",
       "      <td>-0.022472</td>\n",
       "      <td>0.045635</td>\n",
       "      <td>0.049618</td>\n",
       "      <td>0.009245</td>\n",
       "      <td>0.020719</td>\n",
       "      <td>0.010762</td>\n",
       "      <td>0.031821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>universal free health care</td>\n",
       "      <td>-0.013799</td>\n",
       "      <td>0.077828</td>\n",
       "      <td>0.028418</td>\n",
       "      <td>0.013109</td>\n",
       "      <td>0.051120</td>\n",
       "      <td>0.016538</td>\n",
       "      <td>0.017926</td>\n",
       "      <td>-0.027106</td>\n",
       "      <td>0.028668</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.038434</td>\n",
       "      <td>0.050330</td>\n",
       "      <td>0.164079</td>\n",
       "      <td>0.023516</td>\n",
       "      <td>-0.037081</td>\n",
       "      <td>0.026098</td>\n",
       "      <td>-0.019342</td>\n",
       "      <td>0.034655</td>\n",
       "      <td>0.068513</td>\n",
       "      <td>0.082887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>deadly consequence</td>\n",
       "      <td>0.053178</td>\n",
       "      <td>-0.005348</td>\n",
       "      <td>-0.008809</td>\n",
       "      <td>-0.018735</td>\n",
       "      <td>-0.015988</td>\n",
       "      <td>-0.001234</td>\n",
       "      <td>-0.017554</td>\n",
       "      <td>0.020279</td>\n",
       "      <td>-0.061362</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.042913</td>\n",
       "      <td>-0.037350</td>\n",
       "      <td>-0.006825</td>\n",
       "      <td>0.072847</td>\n",
       "      <td>-0.053072</td>\n",
       "      <td>0.063832</td>\n",
       "      <td>0.025820</td>\n",
       "      <td>0.027221</td>\n",
       "      <td>-0.054562</td>\n",
       "      <td>0.014381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>users activity</td>\n",
       "      <td>-0.026125</td>\n",
       "      <td>0.016817</td>\n",
       "      <td>0.005812</td>\n",
       "      <td>0.067683</td>\n",
       "      <td>0.071939</td>\n",
       "      <td>0.070370</td>\n",
       "      <td>-0.053353</td>\n",
       "      <td>0.005770</td>\n",
       "      <td>0.060505</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015617</td>\n",
       "      <td>-0.031431</td>\n",
       "      <td>-0.006912</td>\n",
       "      <td>-0.024569</td>\n",
       "      <td>0.085909</td>\n",
       "      <td>-0.026211</td>\n",
       "      <td>0.053759</td>\n",
       "      <td>-0.108147</td>\n",
       "      <td>-0.009249</td>\n",
       "      <td>-0.034792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>soonthe company</td>\n",
       "      <td>-0.009154</td>\n",
       "      <td>-0.008781</td>\n",
       "      <td>0.026742</td>\n",
       "      <td>-0.005074</td>\n",
       "      <td>-0.028769</td>\n",
       "      <td>0.041692</td>\n",
       "      <td>0.090339</td>\n",
       "      <td>-0.052231</td>\n",
       "      <td>-0.007637</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010862</td>\n",
       "      <td>0.013613</td>\n",
       "      <td>0.014772</td>\n",
       "      <td>-0.023711</td>\n",
       "      <td>0.005862</td>\n",
       "      <td>0.031451</td>\n",
       "      <td>-0.012725</td>\n",
       "      <td>-0.102446</td>\n",
       "      <td>0.021036</td>\n",
       "      <td>0.100148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã 513 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         word     emb_0     emb_1     emb_2     emb_3  \\\n",
       "0               illegal trade  0.088174 -0.024202  0.032902  0.034414   \n",
       "1  universal free health care -0.013799  0.077828  0.028418  0.013109   \n",
       "2          deadly consequence  0.053178 -0.005348 -0.008809 -0.018735   \n",
       "3              users activity -0.026125  0.016817  0.005812  0.067683   \n",
       "4             soonthe company -0.009154 -0.008781  0.026742 -0.005074   \n",
       "\n",
       "      emb_4     emb_5     emb_6     emb_7     emb_8  ...   emb_502   emb_503  \\\n",
       "0 -0.043001  0.047338 -0.000035  0.001882 -0.032775  ... -0.025584  0.000864   \n",
       "1  0.051120  0.016538  0.017926 -0.027106  0.028668  ... -0.038434  0.050330   \n",
       "2 -0.015988 -0.001234 -0.017554  0.020279 -0.061362  ... -0.042913 -0.037350   \n",
       "3  0.071939  0.070370 -0.053353  0.005770  0.060505  ...  0.015617 -0.031431   \n",
       "4 -0.028769  0.041692  0.090339 -0.052231 -0.007637  ...  0.010862  0.013613   \n",
       "\n",
       "    emb_504   emb_505   emb_506   emb_507   emb_508   emb_509   emb_510  \\\n",
       "0  0.052648 -0.022472  0.045635  0.049618  0.009245  0.020719  0.010762   \n",
       "1  0.164079  0.023516 -0.037081  0.026098 -0.019342  0.034655  0.068513   \n",
       "2 -0.006825  0.072847 -0.053072  0.063832  0.025820  0.027221 -0.054562   \n",
       "3 -0.006912 -0.024569  0.085909 -0.026211  0.053759 -0.108147 -0.009249   \n",
       "4  0.014772 -0.023711  0.005862  0.031451 -0.012725 -0.102446  0.021036   \n",
       "\n",
       "    emb_511  \n",
       "0  0.031821  \n",
       "1  0.082887  \n",
       "2  0.014381  \n",
       "3 -0.034792  \n",
       "4  0.100148  \n",
       "\n",
       "[5 rows x 513 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#creating word2vec matrix\n",
    "df_w2v = get_word_embeddings(df_words, column = \"word\", N_batches=100)\n",
    "df_w2v.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>emb_0</th>\n",
       "      <th>emb_1</th>\n",
       "      <th>emb_2</th>\n",
       "      <th>emb_3</th>\n",
       "      <th>emb_4</th>\n",
       "      <th>emb_5</th>\n",
       "      <th>emb_6</th>\n",
       "      <th>emb_7</th>\n",
       "      <th>emb_8</th>\n",
       "      <th>...</th>\n",
       "      <th>emb_502</th>\n",
       "      <th>emb_503</th>\n",
       "      <th>emb_504</th>\n",
       "      <th>emb_505</th>\n",
       "      <th>emb_506</th>\n",
       "      <th>emb_507</th>\n",
       "      <th>emb_508</th>\n",
       "      <th>emb_509</th>\n",
       "      <th>emb_510</th>\n",
       "      <th>emb_511</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>illegal trade</td>\n",
       "      <td>0.088174</td>\n",
       "      <td>-0.024202</td>\n",
       "      <td>0.032902</td>\n",
       "      <td>0.034414</td>\n",
       "      <td>-0.043001</td>\n",
       "      <td>0.047338</td>\n",
       "      <td>-0.000035</td>\n",
       "      <td>0.001882</td>\n",
       "      <td>-0.032775</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025584</td>\n",
       "      <td>0.000864</td>\n",
       "      <td>0.052648</td>\n",
       "      <td>-0.022472</td>\n",
       "      <td>0.045635</td>\n",
       "      <td>0.049618</td>\n",
       "      <td>0.009245</td>\n",
       "      <td>0.020719</td>\n",
       "      <td>0.010762</td>\n",
       "      <td>0.031821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3246</th>\n",
       "      <td>american film studio</td>\n",
       "      <td>0.002946</td>\n",
       "      <td>0.080105</td>\n",
       "      <td>0.009157</td>\n",
       "      <td>0.008486</td>\n",
       "      <td>0.007905</td>\n",
       "      <td>0.099968</td>\n",
       "      <td>-0.016649</td>\n",
       "      <td>-0.058844</td>\n",
       "      <td>-0.048068</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009001</td>\n",
       "      <td>0.017807</td>\n",
       "      <td>0.068661</td>\n",
       "      <td>0.015315</td>\n",
       "      <td>-0.032000</td>\n",
       "      <td>-0.041465</td>\n",
       "      <td>-0.036790</td>\n",
       "      <td>-0.008068</td>\n",
       "      <td>0.060914</td>\n",
       "      <td>0.032913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2299</th>\n",
       "      <td>analyzed hospital discharge datum</td>\n",
       "      <td>-0.026752</td>\n",
       "      <td>0.055819</td>\n",
       "      <td>0.042151</td>\n",
       "      <td>0.044713</td>\n",
       "      <td>-0.014527</td>\n",
       "      <td>-0.101770</td>\n",
       "      <td>0.006108</td>\n",
       "      <td>-0.059279</td>\n",
       "      <td>-0.059515</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002860</td>\n",
       "      <td>0.021987</td>\n",
       "      <td>-0.047937</td>\n",
       "      <td>0.030521</td>\n",
       "      <td>0.013224</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.034310</td>\n",
       "      <td>-0.061723</td>\n",
       "      <td>-0.013282</td>\n",
       "      <td>0.015742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã 513 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   word     emb_0     emb_1     emb_2  \\\n",
       "0                         illegal trade  0.088174 -0.024202  0.032902   \n",
       "3246               american film studio  0.002946  0.080105  0.009157   \n",
       "2299  analyzed hospital discharge datum -0.026752  0.055819  0.042151   \n",
       "\n",
       "         emb_3     emb_4     emb_5     emb_6     emb_7     emb_8  ...  \\\n",
       "0     0.034414 -0.043001  0.047338 -0.000035  0.001882 -0.032775  ...   \n",
       "3246  0.008486  0.007905  0.099968 -0.016649 -0.058844 -0.048068  ...   \n",
       "2299  0.044713 -0.014527 -0.101770  0.006108 -0.059279 -0.059515  ...   \n",
       "\n",
       "       emb_502   emb_503   emb_504   emb_505   emb_506   emb_507   emb_508  \\\n",
       "0    -0.025584  0.000864  0.052648 -0.022472  0.045635  0.049618  0.009245   \n",
       "3246  0.009001  0.017807  0.068661  0.015315 -0.032000 -0.041465 -0.036790   \n",
       "2299  0.002860  0.021987 -0.047937  0.030521  0.013224  0.000185  0.034310   \n",
       "\n",
       "       emb_509   emb_510   emb_511  \n",
       "0     0.020719  0.010762  0.031821  \n",
       "3246 -0.008068  0.060914  0.032913  \n",
       "2299 -0.061723 -0.013282  0.015742  \n",
       "\n",
       "[3 rows x 513 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_w2v.iloc[::150001]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality reduction \n",
    "UMAP https://github.com/lmcinnes/umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(419327, 512)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = [\"emb_\" + str(i) for i in range(512)]\n",
    "embeddings = df_w2v[columns].values\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 57min 46s, sys: 1min 21s, total: 59min 8s\n",
      "Wall time: 6min 8s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(419327, 5)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "umap_embeddings = umap.UMAP(n_neighbors=15, \n",
    "                            n_components=5, \n",
    "                            metric='cosine').fit_transform(embeddings)\n",
    "umap_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = hdbscan.HDBSCAN(min_cluster_size=15,\n",
    "                          metric='euclidean',                      \n",
    "                          cluster_selection_method='eom').fit(umap_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(419327,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cluster labels\n",
    "labels = cluster.labels_\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clusters: 4319\n"
     ]
    }
   ],
   "source": [
    "#number of clusters (key-words/phrases)\n",
    "print(\"Number of clusters:\",labels.max() + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data for LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### get cluster label as most frequent word/phrase of the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>cluster_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>illegal trade</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>universal free health care</td>\n",
       "      <td>3430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>deadly consequence</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>users activity</td>\n",
       "      <td>3461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>soonthe company</td>\n",
       "      <td>4038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         word  cluster_number\n",
       "0               illegal trade              -1\n",
       "1  universal free health care            3430\n",
       "2          deadly consequence              -1\n",
       "3              users activity            3461\n",
       "4             soonthe company            4038"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tmp = df_w2v[['word']].copy()\n",
    "df_tmp['cluster_number'] = labels\n",
    "df_tmp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(419327, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>cluster_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>illegal trade</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>universal free health care</td>\n",
       "      <td>3430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>deadly consequence</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>users activity</td>\n",
       "      <td>3461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>soonthe company</td>\n",
       "      <td>4038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         word  cluster_number\n",
       "0               illegal trade              -1\n",
       "1  universal free health care            3430\n",
       "2          deadly consequence              -1\n",
       "3              users activity            3461\n",
       "4             soonthe company            4038"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_words = pd.DataFrame({'word': list(set(all_NPs + all_Vs))})\n",
    "df_all_words = df_all_words.merge(df_tmp, on='word', how='inner')\n",
    "print(df_all_words.shape)\n",
    "df_all_words.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>cluster_number</th>\n",
       "      <th>cluster_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>illegal trade</td>\n",
       "      <td>-1</td>\n",
       "      <td>noise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222222</th>\n",
       "      <td>teslas laserwindex</td>\n",
       "      <td>53</td>\n",
       "      <td>teslas laserwindex</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      word  cluster_number       cluster_label\n",
       "0            illegal trade              -1               noise\n",
       "222222  teslas laserwindex              53  teslas laserwindex"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#label cluster with noise words as \"noise\"\n",
    "def get_label(n,w):\n",
    "    if n == -1:\n",
    "        return \"noise\"\n",
    "    else:\n",
    "        return w\n",
    "\n",
    "df_all_words['cluster_label'] = df_all_words.apply(lambda x: get_label(x.cluster_number, x.word), axis=1) \n",
    "df_all_words.iloc[::222222]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>cluster_number</th>\n",
       "      <th>cluster_label</th>\n",
       "      <th>word_frequency</th>\n",
       "      <th>word_max_frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>illegal trade</td>\n",
       "      <td>-1</td>\n",
       "      <td>noise</td>\n",
       "      <td>163822</td>\n",
       "      <td>163822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222222</th>\n",
       "      <td>teslas laserwindex</td>\n",
       "      <td>53</td>\n",
       "      <td>teslas laserwindex</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      word  cluster_number       cluster_label  \\\n",
       "0            illegal trade              -1               noise   \n",
       "222222  teslas laserwindex              53  teslas laserwindex   \n",
       "\n",
       "        word_frequency  word_max_frequency  \n",
       "0               163822              163822  \n",
       "222222               1                   1  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_words['word_frequency'] = df_all_words.groupby(['cluster_number', \n",
    "                                                       'cluster_label'])['word'].transform(\"count\")\n",
    "df_all_words['word_max_frequency'] = df_all_words.groupby(['cluster_number'])['word_frequency'].transform(\"max\")\n",
    "df_all_words.iloc[::222222]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>1%</th>\n",
       "      <th>10%</th>\n",
       "      <th>20%</th>\n",
       "      <th>30%</th>\n",
       "      <th>40%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>95%</th>\n",
       "      <th>99%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cluster_number</th>\n",
       "      <td>419327.0</td>\n",
       "      <td>1356.103366</td>\n",
       "      <td>1488.978787</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>801.0</td>\n",
       "      <td>2628.0</td>\n",
       "      <td>4146.0</td>\n",
       "      <td>4318.0</td>\n",
       "      <td>4318.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_frequency</th>\n",
       "      <td>419327.0</td>\n",
       "      <td>64002.325605</td>\n",
       "      <td>79928.760269</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>163822.0</td>\n",
       "      <td>163822.0</td>\n",
       "      <td>163822.0</td>\n",
       "      <td>163822.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_max_frequency</th>\n",
       "      <td>419327.0</td>\n",
       "      <td>64002.325605</td>\n",
       "      <td>79928.760269</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>163822.0</td>\n",
       "      <td>163822.0</td>\n",
       "      <td>163822.0</td>\n",
       "      <td>163822.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       count          mean           std  min   1%  10%  20%  \\\n",
       "cluster_number      419327.0   1356.103366   1488.978787 -1.0 -1.0 -1.0 -1.0   \n",
       "word_frequency      419327.0  64002.325605  79928.760269  1.0  1.0  1.0  1.0   \n",
       "word_max_frequency  419327.0  64002.325605  79928.760269  1.0  1.0  1.0  1.0   \n",
       "\n",
       "                    30%   40%    50%       75%       95%       99%       max  \n",
       "cluster_number     -1.0  57.0  801.0    2628.0    4146.0    4318.0    4318.0  \n",
       "word_frequency      1.0   1.0    1.0  163822.0  163822.0  163822.0  163822.0  \n",
       "word_max_frequency  1.0   1.0    1.0  163822.0  163822.0  163822.0  163822.0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(df_all_words.describe(percentiles=[0.01,0.1,0.20,0.3,0.4,0.5,0.75,0.95,0.99])).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163823 255504\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>cluster_number</th>\n",
       "      <th>cluster_label</th>\n",
       "      <th>word_frequency</th>\n",
       "      <th>word_max_frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>illegal trade</td>\n",
       "      <td>-1</td>\n",
       "      <td>noise</td>\n",
       "      <td>163822</td>\n",
       "      <td>163822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>deadly consequence</td>\n",
       "      <td>-1</td>\n",
       "      <td>noise</td>\n",
       "      <td>163822</td>\n",
       "      <td>163822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>outer solar system moon</td>\n",
       "      <td>-1</td>\n",
       "      <td>noise</td>\n",
       "      <td>163822</td>\n",
       "      <td>163822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fertilizer</td>\n",
       "      <td>-1</td>\n",
       "      <td>noise</td>\n",
       "      <td>163822</td>\n",
       "      <td>163822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>central draw</td>\n",
       "      <td>-1</td>\n",
       "      <td>noise</td>\n",
       "      <td>163822</td>\n",
       "      <td>163822</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       word  cluster_number cluster_label  word_frequency  \\\n",
       "0             illegal trade              -1         noise          163822   \n",
       "2        deadly consequence              -1         noise          163822   \n",
       "5   outer solar system moon              -1         noise          163822   \n",
       "7                fertilizer              -1         noise          163822   \n",
       "12             central draw              -1         noise          163822   \n",
       "\n",
       "    word_max_frequency  \n",
       "0               163822  \n",
       "2               163822  \n",
       "5               163822  \n",
       "7               163822  \n",
       "12              163822  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_words['word_max_frequency'] = df_all_words.groupby(['cluster_number'])['word_frequency'].transform(\"max\")\n",
    "\n",
    "df_tmp_noise = pd.DataFrame(df_all_words[df_all_words['cluster_label'] == \"noise\"])\n",
    "df_tmp_other = df_all_words[df_all_words['cluster_label'] != \"noise\"]\n",
    "print(len(df_tmp_noise),len(df_tmp_other))\n",
    "df_tmp_noise.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4319, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster_number</th>\n",
       "      <th>cluster_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>related hashtag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>1000</td>\n",
       "      <td>good game</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>2000</td>\n",
       "      <td>poopthe upgrade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000</th>\n",
       "      <td>3000</td>\n",
       "      <td>companys ideological echochamber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4000</th>\n",
       "      <td>4000</td>\n",
       "      <td>bill simmons new site</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      cluster_number                     cluster_label\n",
       "0                  0                   related hashtag\n",
       "1000            1000                         good game\n",
       "2000            2000                   poopthe upgrade\n",
       "3000            3000  companys ideological echochamber\n",
       "4000            4000             bill simmons new site"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tmp = df_tmp_other[df_tmp_other['word_max_frequency'] == df_tmp_other['word_frequency']]\n",
    "df_tmp = df_tmp.groupby('cluster_number')['cluster_label'].last().reset_index()\n",
    "print(df_tmp.shape)\n",
    "df_tmp.iloc[::1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(419327, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>222222</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <td>illegal trade</td>\n",
       "      <td>teslas laserwindex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster_number</th>\n",
       "      <td>-1</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster_label</th>\n",
       "      <td>noise</td>\n",
       "      <td>tesla roadster payload</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       0                       222222\n",
       "word            illegal trade      teslas laserwindex\n",
       "cluster_number             -1                      53\n",
       "cluster_label           noise  tesla roadster payload"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_word_clusters = df_all_words[['word', 'cluster_number']]\n",
    "df_word_clusters = df_word_clusters.merge(df_tmp, on='cluster_number', how='left')\n",
    "\n",
    "df_word_clusters['cluster_label'] = df_word_clusters['cluster_label'].fillna(\"noise\")\n",
    "\n",
    "print(df_word_clusters.shape)\n",
    "df_word_clusters.iloc[::222222].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(419327, 3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_word_clusters = df_word_clusters.drop_duplicates('word')\n",
    "df_word_clusters.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      4320.000000\n",
       "mean         97.066435\n",
       "std        2497.764297\n",
       "min          15.000000\n",
       "25%          23.000000\n",
       "50%          36.000000\n",
       "75%          65.000000\n",
       "max      163822.000000\n",
       "Name: word, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = df_word_clusters.groupby('cluster_label')['word'].count()\n",
    "s.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cluster_label\n",
       "zerowaste airport       80\n",
       "ziggy stardust year     18\n",
       "zika hot zone          107\n",
       "ziploc bag              19\n",
       "zombies                 35\n",
       "Name: word, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>cluster_number</th>\n",
       "      <th>cluster_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [word, cluster_number, cluster_label]\n",
       "Index: []"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_word_clusters[df_word_clusters['cluster_label'] == \"zombie internet\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "419327\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster_label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>illegal trade</th>\n",
       "      <td>noise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>universal free health care</th>\n",
       "      <td>envision healthcare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deadly consequence</th>\n",
       "      <td>noise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>users activity</th>\n",
       "      <td>users basic information</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soonthe company</th>\n",
       "      <td>ukrainebased company</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      cluster_label\n",
       "word                                               \n",
       "illegal trade                                 noise\n",
       "universal free health care      envision healthcare\n",
       "deadly consequence                            noise\n",
       "users activity              users basic information\n",
       "soonthe company                ukrainebased company"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create word -> cluster_name series\n",
    "del df_word_clusters['cluster_number']\n",
    "\n",
    "word_cluster_label = df_word_clusters.set_index(\"word\")\n",
    "print(len(word_cluster_label))\n",
    "word_cluster_label.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_cluster_label.to_csv('./transition_files/word_cluster_label.csv')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "GLG - 3_step - Assigning Text Groups.ipynb",
   "toc_visible": true,
   "version": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "305.45px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
